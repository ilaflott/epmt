Timer unit: 1e-06 s

Total time: 15.7334 s
File: ./epmt_job.py
Function: ETL_job_dict at line 229

Line #      Hits         Time  Per Hit   % Time  Line Contents
==============================================================
   229                                           @db_session
   230                                           @profile
   231                                           def ETL_job_dict(metadata, filedict, settings, tarfile=None):
   232                                           # Only fields used for now
   233         1          8.0      8.0      0.0      jobid = metadata['job_pl_id']
   234         1          6.0      6.0      0.0      username = metadata['job_pl_username']
   235                                           #
   236         1        808.0    808.0      0.0      logger.info("Processing job id %s",jobid)
   237         1          5.0      5.0      0.0      hostname = ""
   238         1          4.0      4.0      0.0      file = ""
   239                                           # Damn NAN's for empty strings require converters, and empty integers need floats
   240         1          4.0      4.0      0.0      conv_dic = { 'exename':str, 
   241         1          4.0      4.0      0.0                   'path':str, 
   242         1          4.0      4.0      0.0                   'args':str } 
   243         1          4.0      4.0      0.0      dtype_dic = { 
   244         1          4.0      4.0      0.0          'pid':                        float,
   245         1          4.0      4.0      0.0          'generation':                 float,
   246         1          3.0      3.0      0.0          'ppid':                       float,
   247         1          3.0      3.0      0.0          'pgid':                       float,
   248         1          4.0      4.0      0.0          'sid':                        float,
   249         1          5.0      5.0      0.0          'numtids':                    float }
   250                                           
   251         1          5.0      5.0      0.0      standards = [ "exename","path","args","pid","generation","ppid","pgid","sid","numtids","tid","start","end" ]
   252                                           
   253         1         49.0     49.0      0.0      then = datetime.datetime.now()
   254         1         11.0     11.0      0.0      csvt = datetime.timedelta()
   255         1         15.0     15.0      0.0      earliest_process = datetime.datetime.utcnow()
   256         1         40.0     40.0      0.0      latest_process = datetime.datetime.fromtimestamp(0)
   257                                           #    stdout.write('-')
   258                                           # Hostname, job, metricname objects
   259                                           # Iterate over hosts
   260         1         23.0     23.0      0.0      logger.debug("Iterating over %d hosts for job ID %s, user %s...",len(filedict.keys()),jobid,username)
   261         1       8384.0   8384.0      0.1      u = lookup_or_create_user(username)
   262         1       5991.0   5991.0      0.0      j = create_job(jobid,u,metadata)
   263         1          4.0      4.0      0.0      if not j:
   264                                           # We might have leaked a username to the database here
   265                                           # FIX!        
   266                                                   return None
   267                                           
   268         1          3.0      3.0      0.0      didsomething = False
   269         1          2.0      2.0      0.0      oldcomment = None
   270         1          2.0      2.0      0.0      mns = []
   271         1          2.0      2.0      0.0      tags = []
   272         1          2.0      2.0      0.0      all_tags = []
   273         1          3.0      3.0      0.0      all_procs = []
   274                                           
   275         1          4.0      4.0      0.0      for hostname, files in filedict.iteritems():
   276         1         12.0     12.0      0.0          logger.debug("Processing host %s",hostname)
   277         1       5884.0   5884.0      0.0          h = lookup_or_create_host(hostname)
   278         1          4.0      4.0      0.0          cntmax = len(files)
   279         1          2.0      2.0      0.0          cnt = 0
   280      1000       1981.0      2.0      0.0          for f in files:
   281      1000       8931.0      8.9      0.1              logger.debug("Processing file %s",f)
   282                                           #
   283                                           #            stdout.write('\b')            # erase the last written char
   284                                           #            stdout.write(spinner.next())  # write the next character
   285                                           #            stdout.flush()                # flush stdout buffer (actual character display)
   286                                           #
   287      1000       6935.0      6.9      0.0              csv = datetime.datetime.now()
   288      1000      48810.0     48.8      0.3              rows,comment = extract_tags_from_comment_line(f,tarfile=tarfile)
   289                                           # Check comment/tags cache
   290      1000       2166.0      2.2      0.0              if comment and comment != oldcomment:
   291         1        172.0    172.0      0.0                  logger.info("Missed tag cache %s",comment)
   292         1       3332.0   3332.0      0.0                  tags = lookup_or_create_tags([comment])
   293         1          3.0      3.0      0.0                  oldcomment = comment
   294                                           # Merge all tags into one list for job
   295         1          6.0      6.0      0.0                  all_tags = list(set().union(all_tags,tags))
   296                                           
   297      1000       1365.0      1.4      0.0              if tarfile:
   298                                                           info = tarfile.getmember(f)
   299                                                           flo = tarfile.extractfile(info)
   300                                                       else:
   301      1000       1335.0      1.3      0.0                  flo = f
   302                                                           
   303      1000     458763.0    458.8      2.9              from pandas import read_csv
   304      1000       1526.0      1.5      0.0              pf = read_csv(flo,
   305      1000       1310.0      1.3      0.0                            sep=",",
   306                                           #                          dtype=dtype_dic, 
   307      1000       1330.0      1.3      0.0                            converters=conv_dic,
   308      1000   11412846.0  11412.8     72.5                            skiprows=rows, escapechar='\\')
   309      1000      19960.0     20.0      0.1              if pf.empty:
   310                                                           logger.error("Something wrong with file %s, readcsv returned empty, skipping...",f)
   311                                                           continue
   312                                           
   313                                           # Lookup or create the necessary objects, only happens once!
   314      1000       1784.0      1.8      0.0              if not mns:
   315                                                           # for metric in pf.columns[settings.metrics_offset:].values.tolist():
   316                                                           #     mns[metric] = lookup_or_create_metricname(metric)
   317         1        148.0    148.0      0.0                  mns = pf.columns[settings.metrics_offset:].values.tolist()
   318                                           # Make Process/Thread/Metrics objects in DB
   319      1000    3700512.0   3700.5     23.5              p = load_process_from_pandas(pf, h, j, u, tags, mns)
   320      1000       2095.0      2.1      0.0              if not p:
   321                                                           logger.error("Failed loading from pandas, file %s!",f);
   322                                                           continue
   323      1000       1806.0      1.8      0.0              all_procs.append(p)
   324                                           # Compute duration of job
   325      1000       8822.0      8.8      0.1              if (p.start < earliest_process):
   326         6         32.0      5.3      0.0                  earliest_process = p.start
   327      1000       5678.0      5.7      0.0              if (p.end > latest_process):
   328        11         57.0      5.2      0.0                  latest_process = p.end
   329                                           # Debugging/progress
   330      1000       1554.0      1.6      0.0              cnt += 1
   331      1000      16638.0     16.6      0.1              csvt += datetime.datetime.now() - csv
   332      1000       2010.0      2.0      0.0              if cnt % 1000 == 0:
   333         1        163.0    163.0      0.0                      logger.info("Did %d of %d...%.2f/sec",cnt,cntmax,cnt/csvt.total_seconds())
   334         1          3.0      3.0      0.0                      exit(0)
   335                                           #
   336                                                   if cnt:
   337                                                       didsomething = True
   338                                           
   339                                           #    stdout.write('\b')            # erase the last written char
   340                                           
   341                                               if filedict:
   342                                                   if not didsomething:
   343                                                       logger.warning("Something went wrong in parsing CSV files")
   344                                                       return False
   345                                               else:
   346                                                   logger.warning("Submitting job with no CSV data")
   347                                           
   348                                           # Add sum of tags to job        
   349                                               if all_tags:
   350                                                   logger.info("Adding %d tags to job",len(all_tags))
   351                                                   j.tags.add(all_tags)
   352                                           # Add all processes to job
   353                                               if all_procs:
   354                                                   logger.info("Adding %d processes to job",len(all_procs))
   355                                                   j.processes.add(all_procs)
   356                                           # Update start/end/duration of job
   357                                           #       j.start = earliest_process
   358                                           #        j.end = latest_process
   359                                           #
   360                                           #
   361                                           #
   362                                               j.start = metadata["job_pl_start"]
   363                                               j.end = metadata["job_el_stop"]
   364                                               d = j.end - j.start
   365                                               j.duration = int(d.total_seconds()*1000000)
   366                                               
   367                                           #
   368                                           #
   369                                           #
   370                                               logger.info("Earliest process start: %s",j.start)
   371                                               logger.info("Latest process end: %s",j.end)
   372                                               logger.info("Computed duration of job: %f us, %.2f m",j.duration,j.duration/60000000)
   373                                               now = datetime.datetime.now() 
   374                                               logger.info("Staged import of %d processes, %d threads", 
   375                                                           len(j.processes),len(j.processes.threads))
   376                                               logger.info("Staged import took %s, %f processes per second",
   377                                                           now - then,len(j.processes)/float((now-then).total_seconds()))
   378                                                           
   379                                               return j

