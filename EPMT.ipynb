{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import settings\n",
    "from models import *\n",
    "from epmt_job import setup_orm_db\n",
    "import fnmatch\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "rcParams['figure.figsize'] = [15, 8]\n",
    "setup_orm_db()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def barplot(labels=[], y_val=[], mn=\"None\", yscale=\"log\", title_suffix=\"by executable\"):\n",
    "    index = np.arange(len(labels))\n",
    "    plt.yscale(yscale)\n",
    "    plt.bar(index, y_val)\n",
    "# performance, align='center', alpha=0.5)\n",
    "    plt.xticks(index, labels, fontsize=10, rotation=45)\n",
    "# y_pos, objects)\n",
    "    plt.ylabel(mn)\n",
    "    plt.title(mn+' '+title_suffix)\n",
    "    plt.show()\n",
    "\n",
    "def barplot_stack(labels=[], y_val=[], y2_val=[], mn=[], yscale=\"log\", ylim=(), title_suffix=\"by executable\"):\n",
    "    index = np.arange(len(labels))\n",
    "    plt.yscale(yscale)\n",
    "    p1 = plt.bar(index, y_val, color='r')\n",
    "    p2 = plt.bar(index, y2_val, bottom=y_val, color='g')\n",
    "# performance, align='center', alpha=0.5)\n",
    "    plt.xticks(index, labels, fontsize=10, rotation=45)\n",
    "# y_pos, objects)\n",
    "    plt.ylabel(mn[0]+\"+\"+mn[1])\n",
    "    plt.legend((p1[0], p2[0]), (mn[0], mn[1]))\n",
    "    plt.title(mn[0]+\"+\"+mn[1]+' '+title_suffix)\n",
    "    plt.ylim(ylim)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_list():\n",
    "    q = select(j for j in Job)\n",
    "    return q[:]\n",
    "    \n",
    "# Return list of objects for jobid\n",
    "\n",
    "def get_processes_job(jobid):\n",
    "    # lookup job\n",
    "    try:\n",
    "        j = Job[jobid]\n",
    "    except Exception as e:\n",
    "        print \"not found\",e\n",
    "        return None\n",
    "    print \"Found job\",jobid,\"with\",len(j.processes),\"processes and\",len(j.processes.threads),\"threads\"\n",
    "    return j.processes\n",
    "    \n",
    "# Reduce all processes by executable name and return sums of metric\n",
    "\n",
    "    # we could do this with a query, maybe\n",
    "    # processes=select((p.exename, sum(p.duration), count(p)) for p in Process if p.job == j).order_by(-2)\n",
    "    #    for p in processes:\n",
    "    #        threads += p.threads\n",
    "\n",
    "def get_job_processes_reduce_attr(jobid, attr_name, cutoff=0.0, exelen=10):\n",
    "    processes = get_processes_job(jobid)\n",
    "    if not processes:\n",
    "        return\n",
    "    proc_dict={}\n",
    "    total = 0.0\n",
    "    for p in processes:\n",
    "        exename = p.exename[:exelen]\n",
    "        if exename not in proc_dict:\n",
    "            proc_dict[exename] = {}\n",
    "            proc_dict[exename][\"count\"] = 1\n",
    "            proc_dict[exename][\"threads\"] = len(p.threads)\n",
    "            proc_dict[exename][attr_name] = getattr(p, attr_name)\n",
    "        else:\n",
    "            proc_dict[exename][\"count\"] += 1\n",
    "            proc_dict[exename][\"threads\"] += len(p.threads)\n",
    "            proc_dict[exename][attr_name] += getattr(p, attr_name)\n",
    "        total += getattr(p, attr_name)\n",
    "    \n",
    "    if cutoff > 0.0:\n",
    "        for key in proc_dict.keys():\n",
    "            if proc_dict[key][attr_name] < cutoff:\n",
    "                del proc_dict[key]\n",
    "       \n",
    "    return (total, proc_dict)\n",
    "\n",
    "# Reduce all processes by executable name and return sums of metric\n",
    "\n",
    "def get_job_processes_full_attr(processes, attr_name, cutoff=0.0, exelen=10):\n",
    "    proc_dict={}\n",
    "    total = 0.0\n",
    "    for p in processes:\n",
    "        exename = p.exename[:exelen] \n",
    "        if exename not in proc_dict:\n",
    "            proc_dict[exename] = {}\n",
    "            proc_dict[exename][attr_name] = [getattr(p, attr_name)]\n",
    "            proc_dict[exename][\"start\"] = [getattr(p, \"start\")]                     \n",
    "        else:\n",
    "            proc_dict[exename][attr_name].append(getattr(p, attr_name))\n",
    "            proc_dict[exename][\"start\"].append(getattr(p, \"start\"))\n",
    "        total += getattr(p, attr_name)\n",
    "    \n",
    "    if cutoff > 0.0:\n",
    "        for key in proc_dict.keys():\n",
    "            if proc_dict[key][attr_name] < cutoff:\n",
    "                del proc_dict[key]\n",
    "       \n",
    "    return (total, proc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20294924.moab01.princeton.rdhpcs.noaa.gov from 2019-02-15 17:48:39.246671 to 2019-02-15 19:03:26.082247 by Jeffrey.Durachta took 4486.835576 s.\n",
      "\tPost-processing run, job.name: CM4_piControl_C_atmos_00050101\n",
      "\tPost-processing run, ppr.component: atmos\n",
      "\tPost-processing run, ppr.name: CM4_piControl_C\n",
      "\tPost-processing run, ppr.jobname: CM4_piControl_C_atmos_00050101\n",
      "\tPost-processing run, ppr.oname: 00050101\n",
      "20294925.moab01.princeton.rdhpcs.noaa.gov from 2019-02-15 17:48:39.250163 to 2019-02-15 18:56:55.801626 by Jeffrey.Durachta took 4096.551463 s.\n",
      "\tPost-processing run, job.name: CM4_piControl_C_atmos_level_00050101\n",
      "\tPost-processing run, ppr.component: atmos_level\n",
      "\tPost-processing run, ppr.name: CM4_piControl_C\n",
      "\tPost-processing run, ppr.jobname: CM4_piControl_C_atmos_level_00050101\n",
      "\tPost-processing run, ppr.oname: 00050101\n",
      "20294926.moab01.princeton.rdhpcs.noaa.gov from 2019-02-15 17:48:39.250799 to 2019-02-15 19:12:04.238002 by Jeffrey.Durachta took 5004.987203 s.\n",
      "\tPost-processing run, job.name: CM4_piControl_C_atmos_level_cmip_00050101\n",
      "\tPost-processing run, ppr.component: atmos_level_cmip\n",
      "\tPost-processing run, ppr.name: CM4_piControl_C\n",
      "\tPost-processing run, ppr.jobname: CM4_piControl_C_atmos_level_cmip_00050101\n",
      "\tPost-processing run, ppr.oname: 00050101\n",
      "20294927.moab01.princeton.rdhpcs.noaa.gov from 2019-02-15 17:48:39.255221 to 2019-02-15 18:53:16.331338 by Jeffrey.Durachta took 3877.076117 s.\n",
      "\tPost-processing run, job.name: CM4_piControl_C_atmos_month_aer_00050101\n",
      "\tPost-processing run, ppr.component: atmos_month_aer\n",
      "\tPost-processing run, ppr.name: CM4_piControl_C\n",
      "\tPost-processing run, ppr.jobname: CM4_piControl_C_atmos_month_aer_00050101\n",
      "\tPost-processing run, ppr.oname: 00050101\n",
      "20294929.moab01.princeton.rdhpcs.noaa.gov from 2019-02-15 17:48:39.250164 to 2019-02-15 18:41:00.026465 by Jeffrey.Durachta took 3140.776301 s.\n",
      "\tPost-processing run, job.name: CM4_piControl_C_ocean_annual_1x1deg_00050101\n",
      "\tPost-processing run, ppr.component: ocean_annual_1x1deg\n",
      "\tPost-processing run, ppr.name: CM4_piControl_C\n",
      "\tPost-processing run, ppr.jobname: CM4_piControl_C_ocean_annual_1x1deg_00050101\n",
      "\tPost-processing run, ppr.oname: 00050101\n",
      "20294930.moab01.princeton.rdhpcs.noaa.gov from 2019-02-15 17:48:39.247442 to 2019-02-15 18:17:11.148370 by Jeffrey.Durachta took 1711.900928 s.\n",
      "\tPost-processing run, job.name: CM4_piControl_C_ocean_bling_1x1deg_00050101\n",
      "\tPost-processing run, ppr.component: ocean_bling_1x1deg\n",
      "\tPost-processing run, ppr.name: CM4_piControl_C\n",
      "\tPost-processing run, ppr.jobname: CM4_piControl_C_ocean_bling_1x1deg_00050101\n",
      "\tPost-processing run, ppr.oname: 00050101\n",
      "20294931.moab01.princeton.rdhpcs.noaa.gov from 2019-02-15 17:48:39.249980 to 2019-02-15 19:09:26.921158 by Jeffrey.Durachta took 4847.671178 s.\n",
      "\tPost-processing run, job.name: CM4_piControl_C_tracer_level_00050101\n",
      "\tPost-processing run, ppr.component: tracer_level\n",
      "\tPost-processing run, ppr.name: CM4_piControl_C\n",
      "\tPost-processing run, ppr.jobname: CM4_piControl_C_tracer_level_00050101\n",
      "\tPost-processing run, ppr.oname: 00050101\n"
     ]
    }
   ],
   "source": [
    "js = get_job_list()\n",
    "for j in js:\n",
    "    print j.jobid,\"from\",j.start,\"to\",j.end,\"by\",j.user.name,\"took\",j.duration/1e6,\"s.\"\n",
    "    if j.ppr:\n",
    "        print \"\\t\",\"Post-processing run, job.name:\",j.jobname\n",
    "        print \"\\t\",\"Post-processing run, ppr.component:\",j.ppr.component\n",
    "        print \"\\t\",\"Post-processing run, ppr.name:\",j.ppr.name\n",
    "        print \"\\t\",\"Post-processing run, ppr.jobname:\",j.ppr.jobname\n",
    "        print \"\\t\",\"Post-processing run, ppr.oname:\",j.ppr.oname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = js[0].jobid\n",
    "total, proc_dict = get_job_processes_reduce_attr(jobid=j, attr_name='duration', cutoff=1000000.0)\n",
    "labels = []\n",
    "y_val = []\n",
    "y_val2 = []\n",
    "y_val3 = []\n",
    "labels = sorted(proc_dict.keys())\n",
    "labels = sorted(proc_dict, key=lambda k: (proc_dict[k][\"duration\"]), reverse=True)\n",
    "for k in labels:\n",
    "    value = proc_dict[k]\n",
    "    y_val3.append(value[\"duration\"]/value[\"count\"])\n",
    "    y_val.append(value[\"duration\"])\n",
    "    y_val2.append(value[\"count\"])\n",
    "    \n",
    "barplot(labels=labels,y_val=y_val,mn=\"wall clock duration\")\n",
    "barplot(labels=labels,y_val=y_val2,mn=\"invocations\")\n",
    "barplot(labels=labels,y_val=y_val3,mn=\"average wall clock duration\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return list of objects for jobid\n",
    "\n",
    "def get_processes_job_filter(jobid, pat=None):\n",
    "    query = select ((p.exename, p.start, p.duration) for p in Process \n",
    "                    if p.job in select(j for j in Job if j.jobid == jobid)).order_by(2)\n",
    "    if pat:\n",
    "        query = query.filter(lambda p, q, r: p.startswith(pat))\n",
    "    return query[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_processes_job_filter(jobid=j)    \n",
    "b = zip(*a)\n",
    "plt.plot([],[])\n",
    "plt.scatter(b[1],b[2])\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame( { 'time': b[1], 'duration': b[2] })\n",
    "df['time'] = pd.to_numeric(df['time'])\n",
    "df.plot.hexbin(x='time', y='duration', gridsize=25)\n",
    "\n",
    "#    value[\"duration\"]\n",
    "    #y_val.append()\n",
    "#    print value[\"start\"]\n",
    "    #x_val.append(value[\"start\"])\n",
    "\n",
    "#x_val = [i for i in range(len(y_val))]\n",
    "#print x_val, len(y_val)\n",
    "##barplot(labels=labels,y_val=y_val3,mn=\"average wall clock duration\")\n",
    "#barplot(labels=labels,y_val=y_val,mn=\"wall clock duration\")\n",
    "#barplot(labels=labels,y_val=y_val2,mn=\"invocations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_quantiles(frame):\n",
    "    retval = frame.quantile([.5,.999])\n",
    "    return retval\n",
    "\n",
    "def get_outliers(pdf, metric):\n",
    "    frame_quantiles = compute_quantiles(pdf[metric])\n",
    "    return pdf[pdf[metric] > frame_quantiles[.999]]\n",
    "\n",
    "def print_outliers(d, metric):\n",
    "    if len(d.index):\n",
    "        print \"\\t\",len(d.index),\"outliers in metric\",metric,\"mean\",d[metric].describe()[\"mean\"] \n",
    "    for index, row in d.iterrows():\n",
    "        thr = row['thread']\n",
    "        proc = thr.process\n",
    "        print \"\\t\",thr,proc,proc.exename+\"(\"+str(proc.pid)+\") at\",proc.start,metric,row[metric]\n",
    "        \n",
    "def remove_outliers(dfi, dfol):\n",
    "#    print len(dfi),list(dfi)\n",
    "#    print len(dfol),list(dfol)\n",
    "    dfi = dfi[~dfi.thread.isin(dfol.thread)]\n",
    "#    print len(dfi)\n",
    "    return dfi\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Job[u'20294924.moab01.princeton.rdhpcs.noaa.gov']]\n",
      "arch 253\n",
      "basename 36\n",
      "bash 799\n",
      "cat 89\n",
      "chmod 164\n",
      "cut 4316\n",
      "date 47\n",
      "df 1354\n",
      "dmget 4\n",
      "du 2\n",
      "expr 6\n",
      "find 1\n",
      "fregrid 2\n",
      "getopt 42\n",
      "globus-url-copy 340\n",
      "grep 782\n",
      "grid-proxy-info 497\n",
      "head 1204\n",
      "host 4440\n",
      "id 6\n",
      "list_ncvars.exe 40\n",
      "ln 284\n",
      "logger 6\n",
      "ls 72\n",
      "make 1354\n",
      "mkdir 171\n",
      "modulecmd 11\n",
      "mv 293\n",
      "ncatted 198\n",
      "ncdump 771\n",
      "ncexists 42\n",
      "ncks 91\n",
      "ncra 12\n",
      "perl 558\n",
      "PLEV.exe 6\n",
      "pwd 342\n",
      "python 12\n",
      "python2.7 6\n",
      "readlink 244\n",
      "rm 53\n",
      "sed 585\n",
      "sleep 253\n",
      "sort 372\n",
      "tail 1354\n",
      "tar 1\n",
      "tcsh 13080\n",
      "test 99\n",
      "time 744\n",
      "touch 165\n",
      "tr 281\n",
      "uberftp 2024\n",
      "uptime 506\n",
      "uuidgen 1607\n",
      "wc 4\n",
      "which 2289\n",
      "[Job[u'20294924.moab01.princeton.rdhpcs.noaa.gov']]\n",
      "arch 253\n",
      "basename 36\n",
      "bash 799\n",
      "cat 89\n",
      "chmod 164\n",
      "cut 4316\n",
      "date 47\n",
      "df 1354\n",
      "dmget 4\n",
      "du 2\n",
      "expr 6\n",
      "find 1\n",
      "fregrid 2\n",
      "getopt 42\n",
      "globus-url-copy 340\n",
      "grep 782\n",
      "grid-proxy-info 497\n",
      "head 1204\n",
      "host 4440\n",
      "id 6\n",
      "list_ncvars.exe 40\n",
      "ln 284\n",
      "logger 6\n",
      "ls 72\n",
      "make 1354\n",
      "mkdir 171\n",
      "modulecmd 11\n",
      "mv 293\n",
      "ncatted 198\n",
      "ncdump 771\n",
      "ncexists 42\n",
      "ncks 91\n",
      "ncra 12\n",
      "perl 558\n",
      "PLEV.exe 6\n",
      "pwd 342\n",
      "python 12\n",
      "python2.7 6\n",
      "readlink 244\n",
      "rm 53\n",
      "sed 585\n",
      "sleep 253\n",
      "sort 372\n",
      "tail 1354\n",
      "tar 1\n",
      "tcsh 13080\n",
      "test 99\n",
      "time 744\n",
      "touch 165\n",
      "tr 281\n",
      "uberftp 2024\n",
      "uptime 506\n",
      "uuidgen 1607\n",
      "wc 4\n",
      "which 2289\n"
     ]
    }
   ],
   "source": [
    "tofind = [ \"delayacct_blkio_time\",\"usertime\",\"invol_ctxsw\",\"time_oncpu\",\"time_waiting\",\"systemtime\" ]\n",
    "\n",
    "def get_df_all_process(jids,exe):\n",
    "    q = Process.select(lambda p: p.job in jids and p.exename==exe).without_distinct()\n",
    "#    print \"exe\",exe,\"ran\",len(q),\"times\"\n",
    "    q = select(p.threads.metrics for p in q).without_distinct()\n",
    "# order by is important as it always produces the same order of threads\n",
    "    q = select((m.value,m.metricname.name,m.thread) for m in q).without_distinct().order_by(3)\n",
    "# make lists\n",
    "    meas = {}\n",
    "    for m in q[:]:\n",
    "        if m[1] not in meas:\n",
    "            meas[m[1]] = [ (m[0], m[2]) ]\n",
    "        else:\n",
    "            meas[m[1]].append( (m[0], m[2]) )\n",
    "# make df\n",
    "    df = pd.DataFrame()\n",
    "    for k in tofind:\n",
    "        if k in meas:\n",
    "            v,t = zip(*meas[k])\n",
    "            df[k] = v\n",
    "            if 'thread' not in df.columns:\n",
    "                df['thread'] = t\n",
    "    return df\n",
    "\n",
    "def get_filter_criteria(by_jids):\n",
    "# First compute averages of filter/reference jobs\n",
    "    print by_jids\n",
    "    q1 = Process.select(lambda p: p.job in by_jids).without_distinct()\n",
    "    q1 = select(p.exename for p in q1).order_by(1) #.without_distinct()\n",
    "    criteria = {}\n",
    "    for exe in q1[:]:\n",
    "        df = get_df_all_process(by_jids,exe)\n",
    "        print exe,len(df)\n",
    "        outlier_dfs=[]\n",
    "        outlier_procs=[]\n",
    "        for metric in tofind:\n",
    "            b = get_outliers(df[['thread',metric]].copy(),metric)\n",
    "            #print_outliers(b,metric)\n",
    "            outlier_dfs.append(b)\n",
    "            for index, row in b.iterrows():\n",
    "                outlier_procs.append(row['thread'].process)\n",
    "                #, metric))\n",
    "        #print \"Processes with more than one outlier\"\n",
    "        #procs,metrics = zip(*outlier_procs)\n",
    "        procs = outlier_procs\n",
    "        dfvc = pd.DataFrame({'thread': procs})\n",
    "        vc = dfvc['thread'].value_counts()\n",
    "        vc = vc[ vc != 1]\n",
    "        for index, value in vc.iteritems():\n",
    "#            print index,index.exename,\"on\",index.host.name,\"at\",index.start,\"for\",index.duration\n",
    "#        if len(vc):\n",
    "#            vc.plot.bar(subplots=True,title=index.exename+\" processes with > 1 outlier\",color=['darkblue'])\n",
    "#            plt.show()\n",
    "# FIX:      We should record which outlier(s) for each process!\n",
    "            pass\n",
    "        newdf = df\n",
    "        for d in outlier_dfs:\n",
    "            newdf = remove_outliers(newdf,d)\n",
    "#        print df.describe()\n",
    "        criteria[exe] = newdf.describe()\n",
    "    return criteria\n",
    "#\n",
    "# If we get here, we now have, by executable, a set of criteria to filter the input jobs\n",
    "#\n",
    "def filter_jobs(jids, exe_criteria):\n",
    "    print jids\n",
    "    q1 = Process.select(lambda p: p.job in jids).without_distinct()\n",
    "    q1 = select(p.exename for p in q1).order_by(1) #.without_distinct()\n",
    "    criteria = {}\n",
    "    for exe in q1[:]:\n",
    "        df = get_df_all_process(jids,exe)\n",
    "        print exe,len(df)\n",
    "        # for each column/metric\n",
    "        for column in df:\n",
    "            if column == 'thread':\n",
    "                continue\n",
    "            metric = column\n",
    "            if metric not in tofind:\n",
    "                continue\n",
    "            #print \"checking metric\",metric,\"against\",exe\n",
    "            #print df.loc[df[metric] >= 0]\n",
    "        # for each row\n",
    "        #for metric in tofind:\n",
    "            \n",
    "\n",
    "criteria = get_filter_criteria([js[0]])        \n",
    "filter_jobs([js[0]],criteria)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Lets examine tcsh\n",
    "\n",
    "q = Process.select(lambda p: p.job==js[0] and p.exename==\"tcsh\").without_distinct()\n",
    "q = select(p.threads.metrics for p in q).without_distinct()\n",
    "q = select((m.value,m.metricname.name,m.thread) for m in q).without_distinct().order_by(3)\n",
    "# order by is important as it always produces the same order of threads\n",
    "meas = {}\n",
    "for m in q[:]:\n",
    "    if m[1] not in meas:\n",
    "        meas[m[1]] = [ (m[0], m[2]) ]\n",
    "    else:\n",
    "        meas[m[1]].append( (m[0], m[2]) )\n",
    "\n",
    "# Very important to be sorted by thread object here!\n",
    "\n",
    "tofind = [ \"delayacct_blkio_time\",\"usertime\",\"invol_ctxsw\",\"time_oncpu\",\"time_waiting\",\"systemtime\" ]\n",
    "df = pd.DataFrame()\n",
    "for k in tofind:\n",
    "    if k in meas:\n",
    "        v,t = zip(*meas[k])\n",
    "        df[k] = v\n",
    "        if 'thread' not in df.columns:\n",
    "            df['thread'] = t\n",
    "\n",
    "# TEST\n",
    "#t = Thread[41211]\n",
    "#print t,t.process\n",
    "#print t.metrics.value\n",
    "# Thread[23153] Process[20602] tcsh at 2019-02-15 18:46:10.422353 delayacct_blkio_time 10000.0\n",
    "# Thread[38021] Process[33690] tcsh at 2019-02-15 18:01:31.958077 delayacct_blkio_time 2520000.0\n",
    "        \n",
    "\n",
    "outlier_dfs=[]\n",
    "outlier_procs=[]\n",
    "for metric in tofind:\n",
    "    print\n",
    "#    a = pd.DataFrame()\n",
    "    b = pd.DataFrame()\n",
    "    b = get_outliers(df[['thread',metric]].copy(),metric)\n",
    "    print_outliers(b,metric)\n",
    "    outlier_dfs.append(b)\n",
    "    for index, row in b.iterrows():\n",
    "            outlier_procs.append(row['thread'].process) \n",
    "\n",
    "#print outliers\n",
    "print \"Processes with more than one outlier\"\n",
    "dfvc = pd.DataFrame({'thread': outlier_procs})\n",
    "vc = dfvc['thread'].value_counts()\n",
    "vc = vc[ vc != 1]\n",
    "#badboys = pd.DataFrame(columns=[\"key\",\"exe\",\"host\",\"time\",\"duration_us\"])\n",
    "for index, value in vc.iteritems():\n",
    "        print index,index.exename,\"on\",index.host.name,\"at\",index.start,\"for\",index.duration\n",
    "ax = vc.plot.bar(title=\"Processes with more than one outlier\",color=['darkblue'])\n",
    "\n",
    "\n",
    "newdf = df\n",
    "for d in outlier_dfs:\n",
    "    newdf = remove_outliers(newdf,d)\n",
    "\n",
    "print df.describe()\n",
    "print newdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#df = pd.DataFrame({'Duration': q[:]})\n",
    "#print df.describe()\n",
    "#array = [durs]\n",
    "#plt.boxplot(array,showmeans=True,whis=99)\n",
    "#plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    for key, value in proc_dict.iteritems():\n",
    "#        if value[\"threads\"] > value[\"count\"]:\n",
    "#            print key, value[\"duration\"], total, value[\"duration\"]*100.0/total \n",
    "#        names[\"foo\"] += 1\n",
    "#        attr[p.exename] += p.duration\n",
    "\n",
    "\n",
    "\n",
    "#jobs=select(j for j in Job if j.jobid == jobid)\n",
    "#for j in jobs:\n",
    "#    print \"Job found:\",j.jobname, j.jobid\n",
    "\n",
    "# print \"TOTAL:\",len(processes)\n",
    "#print processes\n",
    "#for p in processes:\n",
    "#    print p\n",
    "#processes=select((p.exename, p.duration) for p in Process if p.job == j and p.exename == \"tcsh\").order_by(-2)\n",
    "#print \"TCSH:\", len(processes)\n",
    "#print \"SUM:\",sum(p.duration for p in Process if p.job == j and p.exename == \"tcsh\")\n",
    "# for p in processes:\n",
    "#    print p[1]\n",
    "# Slice up tuples into X and Y\n",
    "# print labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    \n",
    "    Process.select(lambda p: p.job == jobid)\n",
    "    \n",
    "    j.processes w# lookup job\n",
    "\n",
    "\n",
    "    doit = False\n",
    "        for pat in exepatlist:\n",
    "            if fnmatch.fnmatch(p.exename, pat):\n",
    "                doit = True\n",
    "                break\n",
    "        if not doit:\n",
    "            continue\n",
    "total, proc_dict = get_job_processes_full_attr(jobid='19917749.moab01.princeton.rdhpcs.noaa.gov', attr_name='duration', exepatlist=[\"gl*\"])\n",
    "\n",
    "#print proc_dict\n",
    "x_val = []\n",
    "y_val = []\n",
    "for key, value in proc_dict.iteritems():\n",
    "    plt.plot([ i for i in range(len(value[\"start\"]))],value[\"start\"])\n",
    "    plt.show()\n",
    "\n",
    "print value[\"start\"]\n",
    "\n",
    "#threads=select(p.threads for p in Process if p.job == j)\n",
    "#print \"TOTAL:\",len(threads)\n",
    "#print j\n",
    "metricnames=select(m.name for m in MetricName)[:]\n",
    "#print metricnames, len(metricnames)\n",
    "\n",
    "values=select((m.thread.process.exename, m.metricname.name, sum(m.value)) for m in Metric if m.thread.process.job == j and m.thread.process.exename == 'which').order_by(2)\n",
    "#metricname == MetricName[\"usertime\"])[:10]\n",
    "#print len(values), values[:]\n",
    "# foundmetricnames=[t[1] for t in values][:len(metricnames)]\n",
    "# print foundmetricnames,len(foundmetricnames)\n",
    "numexes = len(values)/len(metricnames)\n",
    "\n",
    "# Iterate over metrics, using number of executables at a time\n",
    "for offset in range(0,len(values),numexes):\n",
    "    mn = (values[:])[offset][1]\n",
    "    procnames = [p[0] for p in values[offset:offset+numexes]]\n",
    "    y_val = [p[2] for p in values[offset:offset+numexes]]\n",
    "    if all(i == 0.0 for i in y_val):\n",
    "        print offset,mn,\"had no non-zero values\"\n",
    "    else:\n",
    "        print offset, mn\n",
    "        print procnames\n",
    "        print y_val\n",
    "        #barplot(labels=procnames,y_val=y_val,mn=mn)\n",
    "\n",
    "values=select((m.thread.process.pid, m.value) for m in Metric if m.metricname.name == \"rssmax\" and m.thread.process.exename == 'which').order_by(2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values=select((m.thread.process.exename, sum(m.thread.process.duration), m.metricname.name, sum(m.value)) for m in Metric if m.metricname.name == \"systemtime\" or m.metricname.name == \"usertime\" ).order_by(3)\n",
    "print len(values)\n",
    "i=len(values)/2\n",
    "print i,values[0:1]\n",
    "print values[64:65]\n",
    "procnames = [p[0] for p in values[0:i]]\n",
    "y_val1 = [p[3] for p in values[0:i]]\n",
    "y_val2 = [p[3] for p in values[i:len(values)]]\n",
    "barplot_stack(labels=procnames,y_val=y_val1, y2_val=y_val2,mn=[\"systemtime\", \"usertime\"],yscale=\"linear\",ylim=(0,100000000))\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(values[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in processes:\n",
    "    print count(p.threads), p.exename, p.duration\n",
    "    #s um(p.threads.duration), p.threads.metrics\n",
    "    threads=select (t for t in Thread if t.process == p)\n",
    "    for t in threads:\n",
    "            print \"\\t\", t.tid, t.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select((p.exename, count(p)) for p in Process if p.job == j).without_distinct()[:]\n",
    "                                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
