{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"EPMT Experiment Performance Management Tool aka WorkflowDB aka PerfMiner This is a tool to collect metadata and performance data about an entire job down to the individual threads in individual processes. This tool uses papiex to perform the process monitoring. This tool is targeted at batch or ephemeral jobs, not daemon processes. The software contained in this repository was written by Philip Mucci of Minimal Metrics LLC. Table of Contents EPMT Table of Contents Verifying Installation !/bin/bash Example job script for Torque or SLURM !/bin/bash Example job script for Torque or SLURM !/bin/bash Example job script for Torque or SLURM !/bin/bash Example job script for Torque or SLURM !/bin/bash Example job script for Torque or SLURM Preamble, collect job metadata and monitor all processes/threads Postamble, disable monitoring and collect job metadata !/bin/bash Example job script for Torque or SLURM Key Source Description Verifying Installation It is best to check your installation and configuration using the epmt check command. Here is an example run from docker via the source tree. You will notice that we bind-mount the parent-directory of epmt to the container. This allows epmt to find the papiex install directory, lying adjacent to the epmt directory. $ docker run --privileged -it --rm -v $PWD/..:/tmp/foo -w /tmp/foo/epmt python-epmt:latest ./epmt check settings.db_params = {'filename': ':memory:', 'provider': 'sqlite'} Pass settings.install_prefix = ../papiex-oss/papiex-oss-install/ ls -l ../papiex-oss/papiex-oss-install/bin/monitor-run /dev/null ls -l ../papiex-oss/papiex-oss-install/lib/libpapiex.so /dev/null ls -l ../papiex-oss/papiex-oss-install/lib/libmonitor.so /dev/null ls -l ../papiex-oss/papiex-oss-install/lib/libpapi.so /dev/null ls -l ../papiex-oss/papiex-oss-install/lib/libpfm.so /dev/null ls -l ../papiex-oss/papiex-oss-install/bin/papi_command_line /dev/null Pass settings.epmt_output_prefix = /tmp/epmt/ mkdir -p /tmp/epmt/ mkdir -p /tmp/epmt/tmp ls -lR /tmp/epmt/ /dev/null rm -rf /tmp/epmt/tmp Pass /proc/sys/kernel/perf_event_paranoid = 2 WARNING:epmt_cmds:restrictive /proc/sys/kernel/perf_event_paranoid value of 2, should be 0 for non-privileged users Pass settings.papiex_options = PERF_COUNT_SW_CPU_CLOCK ../papiex-oss/papiex-oss-install/bin/papi_component_avail| sed -n -e '/Active/,$p' | grep perf_event /dev/null ../papiex-oss/papiex-oss-install/bin/papi_command_line PERF_COUNT_SW_CPU_CLOCK| sed -n -e '/PERF_COUNT_SW_CPU_CLOCK\\ :/,$p' | grep PERF_COUNT_SW_CPU_CLOCK /dev/null Pass WARNING:epmt_cmds:JOB_ID unset: Using session id 1 as JOB_ID WARNING:epmt_cmds:JOB_NAME unset: Using job id 1 as JOB_NAME WARNING:epmt_cmds:JOB_SCRIPTNAME unset: Using process name 1 as JOB_SCRIPTNAME WARNING:epmt_cmds:JOB_USER unset: Using username root as JOB_USER collect functionality (papiex+epmt) epmt run -a /bin/sleep 1 Pass ### Running unit tests with Python's `unittest` module We have a comprehensive set of unit tests. Navigate to the top-level folder in the installation, and run the following command: $ python -m unittest discover {'filename': ':memory:', 'provider': 'sqlite'} setUpModule: importing test/data/misc/ .tgz Imported successfully - job: failed-exitcode processes: 1 rate: 54.5643040323 Imported successfully - job: 685000 processes: 3480 rate: 374.482987496 'setUpModule' took: 10.2743 sec ...... {'filename': ':memory:', 'provider': 'sqlite'} setUpModule: importing test/data/misc/685000.tgz 'setUpModule' took: 0.0117 sec .. {'filename': ':memory:', 'provider': 'sqlite'} setUpModdule: importing test/data/query/ .tgz Imported successfully - job: 685000 processes: 3480 rate: 367.989366376 Imported successfully - job: 685003 processes: 3785 rate: 368.269617338 Imported successfully - job: 685016 processes: 3412 rate: 368.965343103 'setUpModule' took: 31.8878 sec ............... {'filename': ':memory:', 'provider': 'sqlite'} setUpModule: importing test/data/outliers/*.tgz Imported successfully - job: kern-6656-20190614-190245 processes: 10600 rate: 353.525545172 Imported successfully - job: kern-6656-20190614-192044-outlier processes: 10600 rate: 351.265328962 Imported successfully - job: kern-6656-20190614-194024 processes: 10600 rate: 352.45282394 Imported successfully - job: kern-6656-20190614-191138 processes: 10600 rate: 352.341328069 'setUpModule' took: 132.7657 sec ......... Ran 32 tests in 215.512s OK ## Collecting Performance Data Assuming you have EPMT installed and in your path, let's modify a job file: $ cat my_job.sh !/bin/bash Example job script for Torque or SLURM ./compute_the_world --debug This becomes: $ cat my_job_epmt.sh !/bin/bash Example job script for Torque or SLURM epmt start epmt run ./compute_the_world --debug epmt stop Or more succintlty by automating the start/stop cycle with the **--auto** or **-a** flag: $ cat my_job_epmt2.sh !/bin/bash Example job script for Torque or SLURM epmt -a run ./compute_the_world --debug But usually we want to run more than one executable. We could have any number of run statements: $ cat my_job_epmt3.sh !/bin/bash Example job script for Torque or SLURM epmt start epmt run ./initialize_the_world --random epmt run ./compute_the_world epmt run ./postprocess_the_world epmt stop Let's skip all the markup, as we can do it with only environment variables. **EPMT** provides the configuration to export to the environment through the **source** command. The use for this is in a job file and is meant to be evaluated by the running shell, be that some form of Bash or Csh. **epmt source** just prints the required environment variables in Bash format **unless either the SHELL or _ environment variable ends in csh**. **Note the unset of LD_PRELOAD before stop!** This line is to prevent the data collection routine from running on **epmt stop** itself. $ cat my_job_bash.sh !/bin/bash Example job script for Torque or SLURM Preamble, collect job metadata and monitor all processes/threads epmt start eval epmt source ./initialize_the_world --random ./compute_the_world ./postprocess_the_world Postamble, disable monitoring and collect job metadata unset LD_PRELOAD epmt stop Here's an example for Csh, when run interactively, $ /bin/csh epmt -j1 source setenv PAPIEX_OPTIONS PERF_COUNT_SW_CPU_CLOCK; setenv PAPIEX_OUTPUT /tmp/epmt/1/; setenv LD_PRELOAD /Users/phil/Work/GFDL/epmt.git/../papiex-oss/papiex-oss-install/lib/libpapiex.so:/Users/phil/Work/GFDL/epmt.git/../papiex-oss/papiex-oss-install/lib/libpapi.so:/Users/phil/Work/GFDL/epmt.git/../papiex-oss/papiex-oss-install/lib/libpfm.so:/Users/phil/Work/GFDL/epmt.git/../papiex-oss/papiex-oss-install/lib/libmonitor.so ## Importing Data Into the Database After collecting the data, jobs (groups of processes) are imported into the database with the **submit** command. This command takes arguments in the form of directories or tar files that must contain a *job_metadata* file. Normal operation is to submit one or more directories: ```epmt submit dir1/ [...]``` One can also submit a list of compressed tar files: ```epmt submit compressed_dir_file.*z [...]``` There is also a mode where the current environment is used to determine where to find the data. ```epmt submit``` ### Examples #### Submitting a directory of compressed job data This might happen at the end of the day via a cron job: $ epmt submit /*tgz ### Submitting data directly from within a job These commands could be part of every users job, or in the batch systems configurable preambles/postambles. $ cat my_job.sh !/bin/bash Example job script for Torque or SLURM echo \"$PBS_JOBID or $SLURM_JOBID\" epmt start epmt run ./compute_the_world --debug epmt stop epmt submit The start/stop cycle can be removed with the **--auto** or **-a** flag, which performs start and stop for you. $ epmt -a run ./debug_the_world --outliers $ epmt submit ### Submitting data from the current session If not inside of a batch environment, **epmt** will *attempt to fake-and-bake a job id*. This is quite useful when just performing interactive runs. **Note you may not be able to submit these jobs to a shared database. The session ID is not guaranteed to be unique across reboots, much less other systems** However, this use case is perfectly acceptable when using a private database. $ epmt start WARNING:epmt_cmds:JOB_ID unset: Using session id 6948 as JOB_ID WARNING:epmt_cmds:JOB_NAME unset: Using job id 6948 as JOB_NAME WARNING:epmt_cmds:JOB_SCRIPTNAME unset: Using process name 6948 as JOB_SCRIPTNAME WARNING:epmt_cmds:JOB_USER unset: Using username phil as JOB_USE$ epmt run ./debug_the_world --outliers $ epmt stop $ epmt submit To initialize a new session leader, consider using the **setsid** command. ## Usage and Configuration **EPMT** gets all of it's configuration from two places, environment variables and the **settings.py** file. One can examine all the current settings by passing the **--help** option. $ ./epmt help usage: epmt [-n] [-d] [-h] [-a] [--drop] [epmt_cmd] [epmt_cmd_args [epmt_cmd_args ...]] positional arguments: epmt_cmd start, run, stop, submit, dump epmt_cmd_args Additional arguments, command dependent optional arguments: -n, --dry-run Don't touch the database -v, --verbose Increase level of verbosity/debug -h, --help Show this help message and exit -a, --auto Do start/stop when running --drop Drop all tables/data and recreate before importing settings.py (overridden by below env. vars): db_params {'host': 'localhost', 'password': 'example', 'user': 'postgres', 'dbname': 'EPMT', 'provider': 'postgres'} debug False input_pattern -papiex-[0-9] -[0-9]*.csv install_prefix ../papiex-oss/papiex-oss-install/ papiex_options PERF_COUNT_SW_CPU_CLOCK epmt_output_prefix /tmp/epmt/ environment variables (overrides settings.py): ## Environment Variables The following variables replace, at run-time, the values in the **db_params** dictionary found in **settings.py**. EPMT_DB_PROVIDER EPMT_DB_USER EPMT_DB_PASSWORD EPMT_DB_HOST EPMT_DB_DBNAME EPMT_DB_FILENAME ## settings.py There are a number of example files provided. See **INSTALL.md** for more details. $ ls settings settings_pg_container.py settings_sqlite_inmem.py settings_pg_localhost.py settings_sqlite_localfile.py $ $ # In memory only, disappears after run $ cp /path/to/install/settings/settings_sqlite_inmem.py /path/to/install/settings.py $ $ # Persistent and on disk $ cp /path/to/install/settings/settings_sqlite_localfile.py /path/to/install/settings.py $ epmt -v -v submit /dir/to/jobdata ## Debugging **EPMT** can be passed noth **-n** (dry-run) and **-v** (verbosity) to help with debugging. Add more **-v** flags to increase the level of information printed. $ epmt -v start Or to attempt a submit without touching the database: $ epmt -v -v -n submit /dir/to/jobdata Also, one can decode and dump the job_metadata file in a dir or compressed dir. $ epmt dump ~/Downloads/yrs05-25.20190221/CM4_piControl_C_atmos_00050101.papiex.gfdl.19712961.tgz exp_component atmos exp_jobname CM4_piControl_C_atmos_00050101 exp_name CM4_piControl_C exp_oname 00050101 job_el_env_changes {} job_el_env_changes_len 0 job_el_from_batch [] job_el_status 0 job_el_stop 2019-02-20 22:13:23.131187 job_pl_env {'LANG': 'en_US', 'PBS_QUEUE': 'batch', 'SHELL': '/bin/csh', 'PBS_ENVIRONMENT': 'PBS_BATCH', 'PAPIEX_TAGS': 'atmos', 'SHLVL': '3', 'PBS_WALLTIME': '216000', 'MOAB_NODELIST': 'pp057.princeton.rdhpcs.noaa.gov', 'PBS_VERSION': 'TORQUE-6.0.2', 'PAPIEX_OUTPUT': '/vftmp/Foo.Bar/pbs20345339/papiex', 'LOADEDMODULES': '', 'LC_TIME': 'C', 'MACHTYPE': 'x86_64', 'PAPIEX_OPTIONS': 'PERF_COUNT_SW_CPU_CLOCK', 'MOAB_GROUP': 'f'} job_pl_env_len 81 job_pl_from_batch [] job_pl_groupnames ['f', 'f'] job_pl_hostname pp057 job_pl_id 20345339.moab01.princeton.rdhpcs.noaa.gov job_pl_jobname CM4_piControl_C_atmos_00050101 job_pl_scriptname CM4_piControl_C_atmos_00050101 job_pl_start 2019-02-20 19:58:41.274267 job_pl_submit 2019-02-20 19:58:41.274463 job_pl_username Foo.Bar ## EPMT under Docker Using the epmt-command docker image, we run **epmt** on a local directory to submit and set the submission DB host environment variable: $ docker run --network=host -ti --rm -v pwd :/app -w /app -e EPMT_DB_HOST= epmt-command:latest -v submit This could be easilt aliased for convenience. # Analysis of EPMT Data Current analytics are performed in an iPython notebook, specifically the SciPy-Notebook as described on [their homepage](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html). If you have Jupyter installed locally **and** you have installed the prerequisite Python modules (see **INSTALL.md**), there is no need to use the Docker image. You can simply load the **EPMT.ipynb** from the source directory in your environment and begin. However, for those without an environment, using Docker (and assuming you build the images as described in **INSTALL.md**): $ docker-compose up notebook Follow the instructions printed to the screen to navigate to **EPMT.ipynb** or try this link [http://localhost:8888/notebooks/EPMT.ipynb]() and enter the encryption key. You must be in the directory where EPMT.ipynb exists when you start the notebook service. Further documentation exists in that file. ## Data Dictionary EPMT collects data both from the job runtime and the applications run in that environment. See the **models/** directory for what fixed data is stored related to each object. Metric data is stored differently and the data collector's data directionary can be found in papiex-oss/README.md. At the time of this writing it looked like this: Key Source Description exename PAPI Name of the application, usually argv[0] path PAPI Path to the application args monitor All arguments to the application not including argv[0] pid getpid() Process id generation monitor Incremented after every exec() ppid getppid() Parent process id pgid getpgid() Process group id sid getsid() Process session id numtids monitor Number of threads caught by instrumentation tid gettid() Thread id start gettimeofday() Microsecond timestamp at start end gettimeofday() Microsecond timestamp at end usertime getrusage(RUSAGE_THREAD) Microsecond user time systemtime getrusage(RUSAGE_THREAD) Microsecond system time rssmax getrusage(RUSAGE_THREAD) Kb max resident set size minflt getrusage(RUSAGE_THREAD) Minor faults (TLB misses/new page frames) majflt getrusage(RUSAGE_THREAD) Major page faults (requiring I/O) inblock getrusage(RUSAGE_THREAD) 512B blocks read from I/O outblock getrusage(RUSAGE_THREAD) 512B blocks written to I/O vol_ctxsw getrusage(RUSAGE_THREAD) Boluntary context switches (yields) invol_ctxsw getrusage(RUSAGE_THREAD) Involuntary context switches (preemptions) num_threads /proc/ /task/ /stat field 20 Threads in process at finish starttime /proc/ /task/ /stat field 22 Timestamp in jiffies after boot thread was started processor /proc/ /task/ /stat field 39 CPU this thread last ran on delayacct_blkio_time /proc/ /task/ /stat field 42 Jiffies process was blocked in D state on I/O device guest_time /proc/ /task/ /stat field 43 Jiffies running a virtual CPU for a guest OS rchar /proc/ /task/ /io line 1 Bytes read via syscall (may come from pagecache not I/O device) wchar /proc/ /task/ /io line 2 Bytes written via syscall (may go to pagecache not I/O device) syscr /proc/ /task/ /io line 3 Read syscalls syscw /proc/ /task/ /io line 4 Write syscalls read_bytes /proc/ /task/ /io line 4 Bytes read from I/O device write_bytes /proc/ /task/ /io line 4 Bytes written to I/O device cancelled_write_bytes /proc/ /task/ /io line 4 Number of bytes discarded by truncation time_oncpu /proc/ /task/ /schedstat Time in jiffies spent running the CPI time_waiting /proc/ /task/ /schedstat Time in jiffies waiting for a run queue while runnable timeslices /proc/ /task/ /schedstat Number of run periods on CPU rdtsc_duration Real time cycle counter duration of thread Additional metrics can be configured either in two ways: * The papiex_options string In **settings.py** if using ```epmt run``` or ```epmt source``` * The value of the **PAPIEX_OPTIONS** environment variable if using ```LD_PRELOAD``` directly. The value of these should be a comma separated string: $ export PAPIEX_OPTIONS=\"PERF_COUNT_SW_CPU_CLOCK,PAPI_CYCLES\" To list available and functioning metrics, use one of the included command line tools: * papi_avail * papi_native_avail * check_events (libpfm) * showevtinfo (libpfm) * perf list (linux) **The PERF_COUNT_SW_* events should work on any system that has the proper /proc/sys/kernel/perf_event_paranoid setting**. One should verify the functionality of the metric using the ```papi_command_line``` tool: $ papi_command_line PERF_COUNT_SW_CPU_CLOCK $ papi_command_line CYCLES ``` Note that often in virtual environments, hardware counters are not often available in the VM.","title":"Readme"},{"location":"#epmt","text":"Experiment Performance Management Tool aka WorkflowDB aka PerfMiner This is a tool to collect metadata and performance data about an entire job down to the individual threads in individual processes. This tool uses papiex to perform the process monitoring. This tool is targeted at batch or ephemeral jobs, not daemon processes. The software contained in this repository was written by Philip Mucci of Minimal Metrics LLC.","title":"EPMT"},{"location":"#table-of-contents","text":"EPMT Table of Contents Verifying Installation !/bin/bash Example job script for Torque or SLURM !/bin/bash Example job script for Torque or SLURM !/bin/bash Example job script for Torque or SLURM !/bin/bash Example job script for Torque or SLURM !/bin/bash Example job script for Torque or SLURM Preamble, collect job metadata and monitor all processes/threads Postamble, disable monitoring and collect job metadata !/bin/bash Example job script for Torque or SLURM Key Source Description","title":"Table of Contents"},{"location":"#verifying-installation","text":"It is best to check your installation and configuration using the epmt check command. Here is an example run from docker via the source tree. You will notice that we bind-mount the parent-directory of epmt to the container. This allows epmt to find the papiex install directory, lying adjacent to the epmt directory. $ docker run --privileged -it --rm -v $PWD/..:/tmp/foo -w /tmp/foo/epmt python-epmt:latest ./epmt check settings.db_params = {'filename': ':memory:', 'provider': 'sqlite'} Pass settings.install_prefix = ../papiex-oss/papiex-oss-install/ ls -l ../papiex-oss/papiex-oss-install/bin/monitor-run /dev/null ls -l ../papiex-oss/papiex-oss-install/lib/libpapiex.so /dev/null ls -l ../papiex-oss/papiex-oss-install/lib/libmonitor.so /dev/null ls -l ../papiex-oss/papiex-oss-install/lib/libpapi.so /dev/null ls -l ../papiex-oss/papiex-oss-install/lib/libpfm.so /dev/null ls -l ../papiex-oss/papiex-oss-install/bin/papi_command_line /dev/null Pass settings.epmt_output_prefix = /tmp/epmt/ mkdir -p /tmp/epmt/ mkdir -p /tmp/epmt/tmp ls -lR /tmp/epmt/ /dev/null rm -rf /tmp/epmt/tmp Pass /proc/sys/kernel/perf_event_paranoid = 2 WARNING:epmt_cmds:restrictive /proc/sys/kernel/perf_event_paranoid value of 2, should be 0 for non-privileged users Pass settings.papiex_options = PERF_COUNT_SW_CPU_CLOCK ../papiex-oss/papiex-oss-install/bin/papi_component_avail| sed -n -e '/Active/,$p' | grep perf_event /dev/null ../papiex-oss/papiex-oss-install/bin/papi_command_line PERF_COUNT_SW_CPU_CLOCK| sed -n -e '/PERF_COUNT_SW_CPU_CLOCK\\ :/,$p' | grep PERF_COUNT_SW_CPU_CLOCK /dev/null Pass WARNING:epmt_cmds:JOB_ID unset: Using session id 1 as JOB_ID WARNING:epmt_cmds:JOB_NAME unset: Using job id 1 as JOB_NAME WARNING:epmt_cmds:JOB_SCRIPTNAME unset: Using process name 1 as JOB_SCRIPTNAME WARNING:epmt_cmds:JOB_USER unset: Using username root as JOB_USER collect functionality (papiex+epmt) epmt run -a /bin/sleep 1 Pass ### Running unit tests with Python's `unittest` module We have a comprehensive set of unit tests. Navigate to the top-level folder in the installation, and run the following command: $ python -m unittest discover {'filename': ':memory:', 'provider': 'sqlite'} setUpModule: importing test/data/misc/ .tgz Imported successfully - job: failed-exitcode processes: 1 rate: 54.5643040323 Imported successfully - job: 685000 processes: 3480 rate: 374.482987496 'setUpModule' took: 10.2743 sec ...... {'filename': ':memory:', 'provider': 'sqlite'} setUpModule: importing test/data/misc/685000.tgz 'setUpModule' took: 0.0117 sec .. {'filename': ':memory:', 'provider': 'sqlite'} setUpModdule: importing test/data/query/ .tgz Imported successfully - job: 685000 processes: 3480 rate: 367.989366376 Imported successfully - job: 685003 processes: 3785 rate: 368.269617338 Imported successfully - job: 685016 processes: 3412 rate: 368.965343103 'setUpModule' took: 31.8878 sec ............... {'filename': ':memory:', 'provider': 'sqlite'} setUpModule: importing test/data/outliers/*.tgz Imported successfully - job: kern-6656-20190614-190245 processes: 10600 rate: 353.525545172 Imported successfully - job: kern-6656-20190614-192044-outlier processes: 10600 rate: 351.265328962 Imported successfully - job: kern-6656-20190614-194024 processes: 10600 rate: 352.45282394 Imported successfully - job: kern-6656-20190614-191138 processes: 10600 rate: 352.341328069 'setUpModule' took: 132.7657 sec ......... Ran 32 tests in 215.512s OK ## Collecting Performance Data Assuming you have EPMT installed and in your path, let's modify a job file: $ cat my_job.sh","title":"Verifying Installation"},{"location":"#binbash","text":"","title":"!/bin/bash"},{"location":"#example-job-script-for-torque-or-slurm","text":"./compute_the_world --debug This becomes: $ cat my_job_epmt.sh","title":"Example job script for Torque or SLURM"},{"location":"#binbash_1","text":"","title":"!/bin/bash"},{"location":"#example-job-script-for-torque-or-slurm_1","text":"epmt start epmt run ./compute_the_world --debug epmt stop Or more succintlty by automating the start/stop cycle with the **--auto** or **-a** flag: $ cat my_job_epmt2.sh","title":"Example job script for Torque or SLURM"},{"location":"#binbash_2","text":"","title":"!/bin/bash"},{"location":"#example-job-script-for-torque-or-slurm_2","text":"epmt -a run ./compute_the_world --debug But usually we want to run more than one executable. We could have any number of run statements: $ cat my_job_epmt3.sh","title":"Example job script for Torque or SLURM"},{"location":"#binbash_3","text":"","title":"!/bin/bash"},{"location":"#example-job-script-for-torque-or-slurm_3","text":"","title":"Example job script for Torque or SLURM"},{"location":"#binbash_4","text":"","title":"!/bin/bash"},{"location":"#example-job-script-for-torque-or-slurm_4","text":"","title":"Example job script for Torque or SLURM"},{"location":"#preamble-collect-job-metadata-and-monitor-all-processesthreads","text":"epmt start eval epmt source","title":"Preamble, collect job metadata and monitor all processes/threads"},{"location":"#postamble-disable-monitoring-and-collect-job-metadata","text":"unset LD_PRELOAD epmt stop Here's an example for Csh, when run interactively, $ /bin/csh epmt -j1 source setenv PAPIEX_OPTIONS PERF_COUNT_SW_CPU_CLOCK; setenv PAPIEX_OUTPUT /tmp/epmt/1/; setenv LD_PRELOAD /Users/phil/Work/GFDL/epmt.git/../papiex-oss/papiex-oss-install/lib/libpapiex.so:/Users/phil/Work/GFDL/epmt.git/../papiex-oss/papiex-oss-install/lib/libpapi.so:/Users/phil/Work/GFDL/epmt.git/../papiex-oss/papiex-oss-install/lib/libpfm.so:/Users/phil/Work/GFDL/epmt.git/../papiex-oss/papiex-oss-install/lib/libmonitor.so ## Importing Data Into the Database After collecting the data, jobs (groups of processes) are imported into the database with the **submit** command. This command takes arguments in the form of directories or tar files that must contain a *job_metadata* file. Normal operation is to submit one or more directories: ```epmt submit dir1/ [...]``` One can also submit a list of compressed tar files: ```epmt submit compressed_dir_file.*z [...]``` There is also a mode where the current environment is used to determine where to find the data. ```epmt submit``` ### Examples #### Submitting a directory of compressed job data This might happen at the end of the day via a cron job: $ epmt submit /*tgz ### Submitting data directly from within a job These commands could be part of every users job, or in the batch systems configurable preambles/postambles. $ cat my_job.sh","title":"Postamble, disable monitoring and collect job metadata"},{"location":"#binbash_5","text":"","title":"!/bin/bash"},{"location":"#example-job-script-for-torque-or-slurm_5","text":"echo \"$PBS_JOBID or $SLURM_JOBID\" epmt start epmt run ./compute_the_world --debug epmt stop epmt submit The start/stop cycle can be removed with the **--auto** or **-a** flag, which performs start and stop for you. $ epmt -a run ./debug_the_world --outliers $ epmt submit ### Submitting data from the current session If not inside of a batch environment, **epmt** will *attempt to fake-and-bake a job id*. This is quite useful when just performing interactive runs. **Note you may not be able to submit these jobs to a shared database. The session ID is not guaranteed to be unique across reboots, much less other systems** However, this use case is perfectly acceptable when using a private database. $ epmt start WARNING:epmt_cmds:JOB_ID unset: Using session id 6948 as JOB_ID WARNING:epmt_cmds:JOB_NAME unset: Using job id 6948 as JOB_NAME WARNING:epmt_cmds:JOB_SCRIPTNAME unset: Using process name 6948 as JOB_SCRIPTNAME WARNING:epmt_cmds:JOB_USER unset: Using username phil as JOB_USE$ epmt run ./debug_the_world --outliers $ epmt stop $ epmt submit To initialize a new session leader, consider using the **setsid** command. ## Usage and Configuration **EPMT** gets all of it's configuration from two places, environment variables and the **settings.py** file. One can examine all the current settings by passing the **--help** option. $ ./epmt help usage: epmt [-n] [-d] [-h] [-a] [--drop] [epmt_cmd] [epmt_cmd_args [epmt_cmd_args ...]] positional arguments: epmt_cmd start, run, stop, submit, dump epmt_cmd_args Additional arguments, command dependent optional arguments: -n, --dry-run Don't touch the database -v, --verbose Increase level of verbosity/debug -h, --help Show this help message and exit -a, --auto Do start/stop when running --drop Drop all tables/data and recreate before importing settings.py (overridden by below env. vars): db_params {'host': 'localhost', 'password': 'example', 'user': 'postgres', 'dbname': 'EPMT', 'provider': 'postgres'} debug False input_pattern -papiex-[0-9] -[0-9]*.csv install_prefix ../papiex-oss/papiex-oss-install/ papiex_options PERF_COUNT_SW_CPU_CLOCK epmt_output_prefix /tmp/epmt/ environment variables (overrides settings.py): ## Environment Variables The following variables replace, at run-time, the values in the **db_params** dictionary found in **settings.py**. EPMT_DB_PROVIDER EPMT_DB_USER EPMT_DB_PASSWORD EPMT_DB_HOST EPMT_DB_DBNAME EPMT_DB_FILENAME ## settings.py There are a number of example files provided. See **INSTALL.md** for more details. $ ls settings settings_pg_container.py settings_sqlite_inmem.py settings_pg_localhost.py settings_sqlite_localfile.py $ $ # In memory only, disappears after run $ cp /path/to/install/settings/settings_sqlite_inmem.py /path/to/install/settings.py $ $ # Persistent and on disk $ cp /path/to/install/settings/settings_sqlite_localfile.py /path/to/install/settings.py $ epmt -v -v submit /dir/to/jobdata ## Debugging **EPMT** can be passed noth **-n** (dry-run) and **-v** (verbosity) to help with debugging. Add more **-v** flags to increase the level of information printed. $ epmt -v start Or to attempt a submit without touching the database: $ epmt -v -v -n submit /dir/to/jobdata Also, one can decode and dump the job_metadata file in a dir or compressed dir. $ epmt dump ~/Downloads/yrs05-25.20190221/CM4_piControl_C_atmos_00050101.papiex.gfdl.19712961.tgz exp_component atmos exp_jobname CM4_piControl_C_atmos_00050101 exp_name CM4_piControl_C exp_oname 00050101 job_el_env_changes {} job_el_env_changes_len 0 job_el_from_batch [] job_el_status 0 job_el_stop 2019-02-20 22:13:23.131187 job_pl_env {'LANG': 'en_US', 'PBS_QUEUE': 'batch', 'SHELL': '/bin/csh', 'PBS_ENVIRONMENT': 'PBS_BATCH', 'PAPIEX_TAGS': 'atmos', 'SHLVL': '3', 'PBS_WALLTIME': '216000', 'MOAB_NODELIST': 'pp057.princeton.rdhpcs.noaa.gov', 'PBS_VERSION': 'TORQUE-6.0.2', 'PAPIEX_OUTPUT': '/vftmp/Foo.Bar/pbs20345339/papiex', 'LOADEDMODULES': '', 'LC_TIME': 'C', 'MACHTYPE': 'x86_64', 'PAPIEX_OPTIONS': 'PERF_COUNT_SW_CPU_CLOCK', 'MOAB_GROUP': 'f'} job_pl_env_len 81 job_pl_from_batch [] job_pl_groupnames ['f', 'f'] job_pl_hostname pp057 job_pl_id 20345339.moab01.princeton.rdhpcs.noaa.gov job_pl_jobname CM4_piControl_C_atmos_00050101 job_pl_scriptname CM4_piControl_C_atmos_00050101 job_pl_start 2019-02-20 19:58:41.274267 job_pl_submit 2019-02-20 19:58:41.274463 job_pl_username Foo.Bar ## EPMT under Docker Using the epmt-command docker image, we run **epmt** on a local directory to submit and set the submission DB host environment variable: $ docker run --network=host -ti --rm -v pwd :/app -w /app -e EPMT_DB_HOST= epmt-command:latest -v submit This could be easilt aliased for convenience. # Analysis of EPMT Data Current analytics are performed in an iPython notebook, specifically the SciPy-Notebook as described on [their homepage](https://jupyter-docker-stacks.readthedocs.io/en/latest/using/selecting.html). If you have Jupyter installed locally **and** you have installed the prerequisite Python modules (see **INSTALL.md**), there is no need to use the Docker image. You can simply load the **EPMT.ipynb** from the source directory in your environment and begin. However, for those without an environment, using Docker (and assuming you build the images as described in **INSTALL.md**): $ docker-compose up notebook Follow the instructions printed to the screen to navigate to **EPMT.ipynb** or try this link [http://localhost:8888/notebooks/EPMT.ipynb]() and enter the encryption key. You must be in the directory where EPMT.ipynb exists when you start the notebook service. Further documentation exists in that file. ## Data Dictionary EPMT collects data both from the job runtime and the applications run in that environment. See the **models/** directory for what fixed data is stored related to each object. Metric data is stored differently and the data collector's data directionary can be found in papiex-oss/README.md. At the time of this writing it looked like this:","title":"Example job script for Torque or SLURM"},{"location":"#key-source-description","text":"exename PAPI Name of the application, usually argv[0] path PAPI Path to the application args monitor All arguments to the application not including argv[0] pid getpid() Process id generation monitor Incremented after every exec() ppid getppid() Parent process id pgid getpgid() Process group id sid getsid() Process session id numtids monitor Number of threads caught by instrumentation tid gettid() Thread id start gettimeofday() Microsecond timestamp at start end gettimeofday() Microsecond timestamp at end usertime getrusage(RUSAGE_THREAD) Microsecond user time systemtime getrusage(RUSAGE_THREAD) Microsecond system time rssmax getrusage(RUSAGE_THREAD) Kb max resident set size minflt getrusage(RUSAGE_THREAD) Minor faults (TLB misses/new page frames) majflt getrusage(RUSAGE_THREAD) Major page faults (requiring I/O) inblock getrusage(RUSAGE_THREAD) 512B blocks read from I/O outblock getrusage(RUSAGE_THREAD) 512B blocks written to I/O vol_ctxsw getrusage(RUSAGE_THREAD) Boluntary context switches (yields) invol_ctxsw getrusage(RUSAGE_THREAD) Involuntary context switches (preemptions) num_threads /proc/ /task/ /stat field 20 Threads in process at finish starttime /proc/ /task/ /stat field 22 Timestamp in jiffies after boot thread was started processor /proc/ /task/ /stat field 39 CPU this thread last ran on delayacct_blkio_time /proc/ /task/ /stat field 42 Jiffies process was blocked in D state on I/O device guest_time /proc/ /task/ /stat field 43 Jiffies running a virtual CPU for a guest OS rchar /proc/ /task/ /io line 1 Bytes read via syscall (may come from pagecache not I/O device) wchar /proc/ /task/ /io line 2 Bytes written via syscall (may go to pagecache not I/O device) syscr /proc/ /task/ /io line 3 Read syscalls syscw /proc/ /task/ /io line 4 Write syscalls read_bytes /proc/ /task/ /io line 4 Bytes read from I/O device write_bytes /proc/ /task/ /io line 4 Bytes written to I/O device cancelled_write_bytes /proc/ /task/ /io line 4 Number of bytes discarded by truncation time_oncpu /proc/ /task/ /schedstat Time in jiffies spent running the CPI time_waiting /proc/ /task/ /schedstat Time in jiffies waiting for a run queue while runnable timeslices /proc/ /task/ /schedstat Number of run periods on CPU rdtsc_duration Real time cycle counter duration of thread Additional metrics can be configured either in two ways: * The papiex_options string In **settings.py** if using ```epmt run``` or ```epmt source``` * The value of the **PAPIEX_OPTIONS** environment variable if using ```LD_PRELOAD``` directly. The value of these should be a comma separated string: $ export PAPIEX_OPTIONS=\"PERF_COUNT_SW_CPU_CLOCK,PAPI_CYCLES\" To list available and functioning metrics, use one of the included command line tools: * papi_avail * papi_native_avail * check_events (libpfm) * showevtinfo (libpfm) * perf list (linux) **The PERF_COUNT_SW_* events should work on any system that has the proper /proc/sys/kernel/perf_event_paranoid setting**. One should verify the functionality of the metric using the ```papi_command_line``` tool: $ papi_command_line PERF_COUNT_SW_CPU_CLOCK $ papi_command_line CYCLES ``` Note that often in virtual environments, hardware counters are not often available in the VM.","title":"Key                     Source                          Description"},{"location":"INSTALL/","text":"EPMT Installation Experiment Performance Management Tool a.k.a Workflow DB This is a tool to collect metadata and performance data about an entire job down to the individual threads in individual processes. This tool uses papiex to perform the process monitoring. This tool is targeted at batch or ephemeral jobs, not daemon processes. The software contained in this repository was written by Philip Mucci of Minimal Metrics LLC. Table of Contents EPMT Installation Table of Contents Requirements Source Code Installation of the Data Collection Libraries Perf Event System Setting Installation of EPMT Configuration Collection Submission Configuring a Database Database Services Database Service Configuration Dropping and Recreating Database Analysis and Visualization Troubleshooting Error: version GLIBC_x.xx not found Appendix Docker Images for the running the EPMT command Testing EPMT Collection with Various Python Versions under Docker Requirements A basic Linux (or container image) with: python (2.6 or higher) pip (python-pip) gcc git For a stock Ubuntu 16.04 (or container): $ apt-get update $ apt-get install -y python python-pip git gcc Source Code Before you start, please make sure you have a copy of EPMT in a directory called build : $ mkdir build $ cd build/ $ git clone https:// user @bitbucket.org/minimalmetrics/epmt.git You also need the papiex data collection libraries in the build directory: $ git clone https://bitbucket.org/minimalmetrics/papiex-oss.git -b papiex-epmt Cloning into 'papiex-oss'... remote: Counting objects: 5274, done. remote: Compressing objects: 100% (3273/3273), done. remote: Total 5274 (delta 2964), reused 3986 (delta 1909) Receiving objects: 100% (5274/5274), 8.54 MiB | 1.70 MiB/s, done. Resolving deltas: 100% (2964/2964), done. Checking connectivity... done. Installation of the Data Collection Libraries Compile the data collection libraries used by EPMT : $ cd papiex-oss/ $ make The we run the data collection tests. If a test is SKIPPED , the test suite will still report a failure. $ make check cd papiex; make PREFIX=/build/papiex-oss/papiex-oss-install LIBPAPIEX=/build/papiex-oss/papiex-oss-install/lib/libpapiex.so check make[1]: Entering directory '/build/papiex-oss/papiex' make -C /build/papiex-oss/papiex/x86_64-Linux -f /build/papiex-oss/papiex/src/Makefile check make[2]: Entering directory '/build/papiex-oss/papiex/x86_64-Linux' cp -Rp /build/papiex-oss/papiex/src/tests/* /build/papiex-oss/papiex/x86_64-Linux/tests cd tests; ./test.sh /build/papiex-oss/papiex-oss-install/bin/monitor-run -i /build/papiex-oss/papiex-oss-install/lib/libpapiex.so Testing papi with PERF_COUNT_SW_CPU_CLOCK... /build/papiex-oss/papiex-oss-install/bin/papi_command_line PERF_COUNT_SW_CPU_CLOCK: PASS(0) 0 errors. Testing tagged runs... sleep 1: PASS ps -fade: PASS host google.com: PASS echo : | tr ':' '\\n': PASS sed -e s/,//g /dev/null: PASS tcsh -f module-test.csh: PASS bash --noprofile -c 'sleep 1': PASS tcsh -f -c 'sleep 1': PASS csh -f -c 'sleep 1': PASS tcsh -f evilcsh.csh: PASS csh -f evilcsh.csh: PASS bash --noprofile sieve.sh 100: PASS tcsh -f sieve.csh 100: PASS csh -f sieve.csh 100: PASS python sieve.py: PASS perl sieve.pl: PASS gcc -Wall unit1.c -o unit1a: PASS gcc -pthread dotprod_mutex.c -o dotprod_mutex: PASS g++ -fopenmp md_openmp.cpp -o md_openmp: PASS gfortran -fopenmp fft_openmp.f90 -o fft_openmp: PASS ./unit1a: PASS ./dotprod_mutex: PASS ./md_openmp: PASS ./fft_openmp: PASS 0 errors. The collection agent is now installed in the papiex-oss-install directory. $ ls papiex-oss-install/ bin include lib share tmp If there are errors, often it is a problem with the a Linux setting that prevents access to performance data, see the next section: Perf Event System Setting For detailed hardware and software performance metrics to collected by non-privileged users, the following setting must be verified/modified: # A value of 3 means the system is totally disabled $ cat /proc/sys/kernel/perf_event_paranoid 3 $ # Allow root and non-root users to use the perf subsystem $ echo 1 /proc/sys/kernel/perf_event_paranoid 1 This isn't necessary unless one would like to collect metrics exposed by PAPI , libpfm and the perfevent subsystems. But collecting this data is, after all, the entire point of this tool. See Stack Overflow for a discussion of the setting. A setting of 1 is perfectly safe for production systems. Installation of EPMT As there is no virtual environment at the moment, the source tree should be copied in its entirety to the target machines. Here we use build/epmt as our source dir, parallel to build/papiex-oss as above. $ cd build $ # $ # We already did this above $ # git clone https:// user @bitbucket.org/minimalmetrics/epmt.git $ cd epmt There are three modes to EPMT usage, collection, submission and analysis, and have an increasing number of dependencies: Collection only requires a minimal Python installation of 2.6.x or higher Submission requires Python packages for data and database interaction Analysis requires Jupyter , an iPython notebook environment, as well as additional python data analysis libraries. Configuration All three modes reference the settings.py file as well as environment variables . EPMT uses uses a in-memory, temporary database by default, see Configuring a Database . $ cat settings.py db_params = {'provider': 'sqlite', 'filename': ':memory:'} papiex_options = PERF_COUNT_SW_CPU_CLOCK epmt_output_prefix = /tmp/epmt/ debug = False input_pattern = *-papiex-[0-9]*-[0-9]*.csv install_prefix = ../papiex-oss/papiex-oss-install/ # DO NOT TOUCH THIS Collection Immediately after installation, but before configuration of settings.py , run the collection regression tests using make check . $ make check make[1]: Entering directory '/build/epmt' PAPIEX_OUTPUT=/build/epmt python -m py_compile *.py models/*.py # Compile everything PAPIEX_OUTPUT=/build/epmt ./epmt -h /dev/null # help path 1 PAPIEX_OUTPUT=/build/epmt ./epmt help /dev/null # help path 2 PAPIEX_OUTPUT=/build/epmt ./epmt start # Generate prolog . . . job_pl_start 2019-03-06 15:29:35.706748 job_pl_submit 2019-03-06 15:29:35.706804 job_pl_username root PAPIEX_OUTPUT=/build/epmt ./epmt -n submit # Submit Python 2.7.12 Tests pass! We can now collect some test data. $ ./epmt -a run firefox $ ls /tmp/epmt/1/ job_metadata linuxkit-025000000001-papiex-14346-0.csv If this fails, then it's likely the papiex installation is either missing or misconfigured in settings.py . The -a flag tells EPMT to treat this run as an entire job . See README.md for further details. Submission In order to submit data to the database, we need to install the dependencies. It is recommended that one use the Docker image which contains all the dependencies and requires no user setup . However, one may install these in a Python virtual environment, to the system Python or the user's local repository, using pip install as below: $ cat requirements.txt pandas==0.17.1 pony==0.7.6 psycopg2-binary==2.7.5 $ pip install --user -r requirements.txt Now we can submit our previous job to the default, in-memory, database defined in settings.py : $ ./epmt -v submit /tmp/epmt/1/ INFO:epmt_cmds:submit_to_db(/tmp/epmt/1/,*-papiex-[0-9]*-[0-9]*.csv,False) INFO:epmt_cmds:Unpickling from /tmp/epmt/1/job_metadata INFO:epmt_cmds:1 files to submit INFO:epmt_cmds:1 hosts found: ['linuxkit-025000000001-'] INFO:epmt_cmds:host linuxkit-025000000001-: 1 files to import INFO:epmt_job:Binding to DB: {'filename': ':memory:', 'provider': 'sqlite'} INFO:epmt_job:Generating mapping from schema... INFO:epmt_job:Processing job id 1 INFO:epmt_job:Creating user root INFO:epmt_job:Creating job 1 INFO:epmt_job:Creating host linuxkit-025000000001- INFO:epmt_job:Creating metricname usertime INFO:epmt_job:Creating metricname systemtime INFO:epmt_job:Creating metricname rssmax INFO:epmt_job:Creating metricname minflt INFO:epmt_job:Creating metricname majflt INFO:epmt_job:Creating metricname inblock INFO:epmt_job:Creating metricname outblock INFO:epmt_job:Creating metricname vol_ctxsw INFO:epmt_job:Creating metricname invol_ctxsw INFO:epmt_job:Creating metricname num_threads INFO:epmt_job:Creating metricname starttime INFO:epmt_job:Creating metricname processor INFO:epmt_job:Creating metricname delayacct_blkio_time INFO:epmt_job:Creating metricname guest_time INFO:epmt_job:Creating metricname rchar INFO:epmt_job:Creating metricname wchar INFO:epmt_job:Creating metricname syscr INFO:epmt_job:Creating metricname syscw INFO:epmt_job:Creating metricname read_bytes INFO:epmt_job:Creating metricname write_bytes INFO:epmt_job:Creating metricname cancelled_write_bytes INFO:epmt_job:Creating metricname time_oncpu INFO:epmt_job:Creating metricname time_waiting INFO:epmt_job:Creating metricname timeslices INFO:epmt_job:Creating metricname rdtsc_duration INFO:epmt_job:Creating metricname PERF_COUNT_SW_CPU_CLOCK INFO:epmt_job:Adding 1 processes to job INFO:epmt_job:Earliest process start: 2019-03-06 15:36:56.948350 INFO:epmt_job:Latest process end: 2019-03-06 15:37:06.996065 INFO:epmt_job:Computed duration of job: 10047715.000000 us, 0.17 m INFO:epmt_job:Staged import of 1 processes, 1 threads INFO:epmt_job:Staged import took 0:00:00.189151, 5.286781 processes per second INFO:epmt_cmds:Committed job 1 to database: Job[u'1'] You are ready to configure a real database. Configuring a Database There is a prebuilt settings.py file to connect to the localhost. $ rm settings.py settings.pyc $ ln -s settings/settings_pg_localhost.py settings.py $ grep db_params settings.py db_params = {'provider': 'postgres', 'user': 'postgres','password': 'example','host': 'localhost', 'dbname': 'EPMT'} The database is ready to go. Database Services If you do not have a postgres database daemon installed and running, it's easiest to use the provided Docker Compose recipe for both the database and the administrative interface: $ docker-compose up adminer db $ docker-compose ps Name Command State Ports -------------------------------------------------------------------------------- epmt_adminer_1 entrypoint.sh docker-php-e ... Up 0.0.0.0:8080- 8080/tcp epmt_db_1 docker-entrypoint.sh postgres Up 0.0.0.0:5432- 5432/tcp These services will export the following ports: 8080 for Adminer , the DB administration interface 5432 for PostGresQL After these are running, one can examine the database using the provided Adminer console: http://localhost:8080/?pgsql=db username=postgres db=EPMT ns=public . Database Service Configuration Persistent data and config present in ./data/postgres . See the below docker-compose.yml file: db: image: postgres volumes: - ./data/postgres:/var/lib/postgresql/data restart: always environment: POSTGRES_USER: postgres POSTGRES_PASSWORD: example POSTGRES_DB: EPMT ports: - 5432:5432 Postgres will self-provision if the above database and user are not found. One could run it directly from the command line using docker . docker run --name postgres -v ./data/postgres:/var/lib/postgresql/data -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=example -e POSTGRES_DB=EPMT -d postgres:latest See https://hub.docker.com/_/postgres/ for documentation of the parameters of the image. Dropping and Recreating Database You can do this with the provided Adminer console: http://localhost:8080/?pgsql=db username=postgres or via the command line with psql . $ sudo su - postgres $ psql -c create database EPMT Analysis and Visualization Here we need a working ipython notebook data analytics environment along with EPMT 's dependencies. It's easiest to build/use the existing the epmt-notebook container image, which uses the supported jupyter/scipy-notebook container image from Docker Hub. $ make . . . $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE epmt-notebook latest 045023fc0ccc About a minute ago 4.3GB epmt-command latest 530fe3198a1d About a minute ago 1.1GB python-epmt latest 5b99ede4828d About a minute ago 1.1GB Once epmt-notebook is built, one starts the notebook via the command line. $ docker-compose up notebook Creating epmt_notebook_1 ... done Attaching to epmt_notebook_1 notebook_1 | Executing the command: jupyter notebook notebook_1 | [I 16:21:22.330 NotebookApp] JupyterLab extension loaded from /opt/conda/lib/python3.6/site-packages/jupyterlab notebook_1 | [I 16:21:22.330 NotebookApp] JupyterLab application directory is /opt/conda/share/jupyter/lab notebook_1 | [I 16:21:22.332 NotebookApp] Serving notebooks from local directory: /home/jovyan notebook_1 | [I 16:21:22.333 NotebookApp] The Jupyter Notebook is running at: notebook_1 | [I 16:21:22.333 NotebookApp] http://(9a7974f0ffb9 or 127.0.0.1):8888/?token=c9d7cb543a82a7a278197b874c789da99a7ed91cd2f84016 notebook_1 | [I 16:21:22.333 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation). notebook_1 | [C 16:21:22.339 NotebookApp] notebook_1 | notebook_1 | Copy/paste this URL into your browser when you connect for the first time, notebook_1 | to login with a token: notebook_1 | http://(9a7974f0ffb9 or 127.0.0.1):8888/?token=c9d7cb543a82a7a278197b874c789da99a7ed91cd2f84016 and then login and load the EPMT.ipynb file. Troubleshooting Error: version GLIBC_x.xx not found The successful deployment of the collector libraries depends on the run-time environment of the target system. More plainly, this means, **do not compile papiex in your development environment, compile it with your target distributions environment. Each target environment should have their own separate papiex-oss-install directory. If you need to do otherwise, there are solutions involving deploying copies of additional libraries . Appendix Docker Images for the running the EPMT command The image epmt-command is the image that contains a working epmt install and all it's dependencies. It's mean to be run as a command with arguments via docker run . See README.md for more details. Testing EPMT Collection with Various Python Versions under Docker One can test EPMT on various versions of python with the following make commands. Each will test against a minimal install of Python, without installing any dependencies. make check-python-native make check-python-2.6 make check-python-2.7 make check-python-3","title":"EPMT Installation"},{"location":"INSTALL/#epmt-installation","text":"Experiment Performance Management Tool a.k.a Workflow DB This is a tool to collect metadata and performance data about an entire job down to the individual threads in individual processes. This tool uses papiex to perform the process monitoring. This tool is targeted at batch or ephemeral jobs, not daemon processes. The software contained in this repository was written by Philip Mucci of Minimal Metrics LLC.","title":"EPMT Installation"},{"location":"INSTALL/#table-of-contents","text":"EPMT Installation Table of Contents Requirements Source Code Installation of the Data Collection Libraries Perf Event System Setting Installation of EPMT Configuration Collection Submission Configuring a Database Database Services Database Service Configuration Dropping and Recreating Database Analysis and Visualization Troubleshooting Error: version GLIBC_x.xx not found Appendix Docker Images for the running the EPMT command Testing EPMT Collection with Various Python Versions under Docker","title":"Table of Contents"},{"location":"INSTALL/#requirements","text":"A basic Linux (or container image) with: python (2.6 or higher) pip (python-pip) gcc git For a stock Ubuntu 16.04 (or container): $ apt-get update $ apt-get install -y python python-pip git gcc","title":"Requirements"},{"location":"INSTALL/#source-code","text":"Before you start, please make sure you have a copy of EPMT in a directory called build : $ mkdir build $ cd build/ $ git clone https:// user @bitbucket.org/minimalmetrics/epmt.git You also need the papiex data collection libraries in the build directory: $ git clone https://bitbucket.org/minimalmetrics/papiex-oss.git -b papiex-epmt Cloning into 'papiex-oss'... remote: Counting objects: 5274, done. remote: Compressing objects: 100% (3273/3273), done. remote: Total 5274 (delta 2964), reused 3986 (delta 1909) Receiving objects: 100% (5274/5274), 8.54 MiB | 1.70 MiB/s, done. Resolving deltas: 100% (2964/2964), done. Checking connectivity... done.","title":"Source Code"},{"location":"INSTALL/#installation-of-the-data-collection-libraries","text":"Compile the data collection libraries used by EPMT : $ cd papiex-oss/ $ make The we run the data collection tests. If a test is SKIPPED , the test suite will still report a failure. $ make check cd papiex; make PREFIX=/build/papiex-oss/papiex-oss-install LIBPAPIEX=/build/papiex-oss/papiex-oss-install/lib/libpapiex.so check make[1]: Entering directory '/build/papiex-oss/papiex' make -C /build/papiex-oss/papiex/x86_64-Linux -f /build/papiex-oss/papiex/src/Makefile check make[2]: Entering directory '/build/papiex-oss/papiex/x86_64-Linux' cp -Rp /build/papiex-oss/papiex/src/tests/* /build/papiex-oss/papiex/x86_64-Linux/tests cd tests; ./test.sh /build/papiex-oss/papiex-oss-install/bin/monitor-run -i /build/papiex-oss/papiex-oss-install/lib/libpapiex.so Testing papi with PERF_COUNT_SW_CPU_CLOCK... /build/papiex-oss/papiex-oss-install/bin/papi_command_line PERF_COUNT_SW_CPU_CLOCK: PASS(0) 0 errors. Testing tagged runs... sleep 1: PASS ps -fade: PASS host google.com: PASS echo : | tr ':' '\\n': PASS sed -e s/,//g /dev/null: PASS tcsh -f module-test.csh: PASS bash --noprofile -c 'sleep 1': PASS tcsh -f -c 'sleep 1': PASS csh -f -c 'sleep 1': PASS tcsh -f evilcsh.csh: PASS csh -f evilcsh.csh: PASS bash --noprofile sieve.sh 100: PASS tcsh -f sieve.csh 100: PASS csh -f sieve.csh 100: PASS python sieve.py: PASS perl sieve.pl: PASS gcc -Wall unit1.c -o unit1a: PASS gcc -pthread dotprod_mutex.c -o dotprod_mutex: PASS g++ -fopenmp md_openmp.cpp -o md_openmp: PASS gfortran -fopenmp fft_openmp.f90 -o fft_openmp: PASS ./unit1a: PASS ./dotprod_mutex: PASS ./md_openmp: PASS ./fft_openmp: PASS 0 errors. The collection agent is now installed in the papiex-oss-install directory. $ ls papiex-oss-install/ bin include lib share tmp If there are errors, often it is a problem with the a Linux setting that prevents access to performance data, see the next section:","title":"Installation of the Data Collection Libraries"},{"location":"INSTALL/#perf-event-system-setting","text":"For detailed hardware and software performance metrics to collected by non-privileged users, the following setting must be verified/modified: # A value of 3 means the system is totally disabled $ cat /proc/sys/kernel/perf_event_paranoid 3 $ # Allow root and non-root users to use the perf subsystem $ echo 1 /proc/sys/kernel/perf_event_paranoid 1 This isn't necessary unless one would like to collect metrics exposed by PAPI , libpfm and the perfevent subsystems. But collecting this data is, after all, the entire point of this tool. See Stack Overflow for a discussion of the setting. A setting of 1 is perfectly safe for production systems.","title":"Perf Event System Setting"},{"location":"INSTALL/#installation-of-epmt","text":"As there is no virtual environment at the moment, the source tree should be copied in its entirety to the target machines. Here we use build/epmt as our source dir, parallel to build/papiex-oss as above. $ cd build $ # $ # We already did this above $ # git clone https:// user @bitbucket.org/minimalmetrics/epmt.git $ cd epmt There are three modes to EPMT usage, collection, submission and analysis, and have an increasing number of dependencies: Collection only requires a minimal Python installation of 2.6.x or higher Submission requires Python packages for data and database interaction Analysis requires Jupyter , an iPython notebook environment, as well as additional python data analysis libraries.","title":"Installation of EPMT"},{"location":"INSTALL/#configuration","text":"All three modes reference the settings.py file as well as environment variables . EPMT uses uses a in-memory, temporary database by default, see Configuring a Database . $ cat settings.py db_params = {'provider': 'sqlite', 'filename': ':memory:'} papiex_options = PERF_COUNT_SW_CPU_CLOCK epmt_output_prefix = /tmp/epmt/ debug = False input_pattern = *-papiex-[0-9]*-[0-9]*.csv install_prefix = ../papiex-oss/papiex-oss-install/ # DO NOT TOUCH THIS","title":"Configuration"},{"location":"INSTALL/#collection","text":"Immediately after installation, but before configuration of settings.py , run the collection regression tests using make check . $ make check make[1]: Entering directory '/build/epmt' PAPIEX_OUTPUT=/build/epmt python -m py_compile *.py models/*.py # Compile everything PAPIEX_OUTPUT=/build/epmt ./epmt -h /dev/null # help path 1 PAPIEX_OUTPUT=/build/epmt ./epmt help /dev/null # help path 2 PAPIEX_OUTPUT=/build/epmt ./epmt start # Generate prolog . . . job_pl_start 2019-03-06 15:29:35.706748 job_pl_submit 2019-03-06 15:29:35.706804 job_pl_username root PAPIEX_OUTPUT=/build/epmt ./epmt -n submit # Submit Python 2.7.12 Tests pass! We can now collect some test data. $ ./epmt -a run firefox $ ls /tmp/epmt/1/ job_metadata linuxkit-025000000001-papiex-14346-0.csv If this fails, then it's likely the papiex installation is either missing or misconfigured in settings.py . The -a flag tells EPMT to treat this run as an entire job . See README.md for further details.","title":"Collection"},{"location":"INSTALL/#submission","text":"In order to submit data to the database, we need to install the dependencies. It is recommended that one use the Docker image which contains all the dependencies and requires no user setup . However, one may install these in a Python virtual environment, to the system Python or the user's local repository, using pip install as below: $ cat requirements.txt pandas==0.17.1 pony==0.7.6 psycopg2-binary==2.7.5 $ pip install --user -r requirements.txt Now we can submit our previous job to the default, in-memory, database defined in settings.py : $ ./epmt -v submit /tmp/epmt/1/ INFO:epmt_cmds:submit_to_db(/tmp/epmt/1/,*-papiex-[0-9]*-[0-9]*.csv,False) INFO:epmt_cmds:Unpickling from /tmp/epmt/1/job_metadata INFO:epmt_cmds:1 files to submit INFO:epmt_cmds:1 hosts found: ['linuxkit-025000000001-'] INFO:epmt_cmds:host linuxkit-025000000001-: 1 files to import INFO:epmt_job:Binding to DB: {'filename': ':memory:', 'provider': 'sqlite'} INFO:epmt_job:Generating mapping from schema... INFO:epmt_job:Processing job id 1 INFO:epmt_job:Creating user root INFO:epmt_job:Creating job 1 INFO:epmt_job:Creating host linuxkit-025000000001- INFO:epmt_job:Creating metricname usertime INFO:epmt_job:Creating metricname systemtime INFO:epmt_job:Creating metricname rssmax INFO:epmt_job:Creating metricname minflt INFO:epmt_job:Creating metricname majflt INFO:epmt_job:Creating metricname inblock INFO:epmt_job:Creating metricname outblock INFO:epmt_job:Creating metricname vol_ctxsw INFO:epmt_job:Creating metricname invol_ctxsw INFO:epmt_job:Creating metricname num_threads INFO:epmt_job:Creating metricname starttime INFO:epmt_job:Creating metricname processor INFO:epmt_job:Creating metricname delayacct_blkio_time INFO:epmt_job:Creating metricname guest_time INFO:epmt_job:Creating metricname rchar INFO:epmt_job:Creating metricname wchar INFO:epmt_job:Creating metricname syscr INFO:epmt_job:Creating metricname syscw INFO:epmt_job:Creating metricname read_bytes INFO:epmt_job:Creating metricname write_bytes INFO:epmt_job:Creating metricname cancelled_write_bytes INFO:epmt_job:Creating metricname time_oncpu INFO:epmt_job:Creating metricname time_waiting INFO:epmt_job:Creating metricname timeslices INFO:epmt_job:Creating metricname rdtsc_duration INFO:epmt_job:Creating metricname PERF_COUNT_SW_CPU_CLOCK INFO:epmt_job:Adding 1 processes to job INFO:epmt_job:Earliest process start: 2019-03-06 15:36:56.948350 INFO:epmt_job:Latest process end: 2019-03-06 15:37:06.996065 INFO:epmt_job:Computed duration of job: 10047715.000000 us, 0.17 m INFO:epmt_job:Staged import of 1 processes, 1 threads INFO:epmt_job:Staged import took 0:00:00.189151, 5.286781 processes per second INFO:epmt_cmds:Committed job 1 to database: Job[u'1'] You are ready to configure a real database.","title":"Submission"},{"location":"INSTALL/#configuring-a-database","text":"There is a prebuilt settings.py file to connect to the localhost. $ rm settings.py settings.pyc $ ln -s settings/settings_pg_localhost.py settings.py $ grep db_params settings.py db_params = {'provider': 'postgres', 'user': 'postgres','password': 'example','host': 'localhost', 'dbname': 'EPMT'} The database is ready to go.","title":"Configuring a Database"},{"location":"INSTALL/#database-services","text":"If you do not have a postgres database daemon installed and running, it's easiest to use the provided Docker Compose recipe for both the database and the administrative interface: $ docker-compose up adminer db $ docker-compose ps Name Command State Ports -------------------------------------------------------------------------------- epmt_adminer_1 entrypoint.sh docker-php-e ... Up 0.0.0.0:8080- 8080/tcp epmt_db_1 docker-entrypoint.sh postgres Up 0.0.0.0:5432- 5432/tcp These services will export the following ports: 8080 for Adminer , the DB administration interface 5432 for PostGresQL After these are running, one can examine the database using the provided Adminer console: http://localhost:8080/?pgsql=db username=postgres db=EPMT ns=public .","title":"Database Services"},{"location":"INSTALL/#database-service-configuration","text":"Persistent data and config present in ./data/postgres . See the below docker-compose.yml file: db: image: postgres volumes: - ./data/postgres:/var/lib/postgresql/data restart: always environment: POSTGRES_USER: postgres POSTGRES_PASSWORD: example POSTGRES_DB: EPMT ports: - 5432:5432 Postgres will self-provision if the above database and user are not found. One could run it directly from the command line using docker . docker run --name postgres -v ./data/postgres:/var/lib/postgresql/data -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=example -e POSTGRES_DB=EPMT -d postgres:latest See https://hub.docker.com/_/postgres/ for documentation of the parameters of the image.","title":"Database Service Configuration"},{"location":"INSTALL/#dropping-and-recreating-database","text":"You can do this with the provided Adminer console: http://localhost:8080/?pgsql=db username=postgres or via the command line with psql . $ sudo su - postgres $ psql -c create database EPMT","title":"Dropping and Recreating Database"},{"location":"INSTALL/#analysis-and-visualization","text":"Here we need a working ipython notebook data analytics environment along with EPMT 's dependencies. It's easiest to build/use the existing the epmt-notebook container image, which uses the supported jupyter/scipy-notebook container image from Docker Hub. $ make . . . $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE epmt-notebook latest 045023fc0ccc About a minute ago 4.3GB epmt-command latest 530fe3198a1d About a minute ago 1.1GB python-epmt latest 5b99ede4828d About a minute ago 1.1GB Once epmt-notebook is built, one starts the notebook via the command line. $ docker-compose up notebook Creating epmt_notebook_1 ... done Attaching to epmt_notebook_1 notebook_1 | Executing the command: jupyter notebook notebook_1 | [I 16:21:22.330 NotebookApp] JupyterLab extension loaded from /opt/conda/lib/python3.6/site-packages/jupyterlab notebook_1 | [I 16:21:22.330 NotebookApp] JupyterLab application directory is /opt/conda/share/jupyter/lab notebook_1 | [I 16:21:22.332 NotebookApp] Serving notebooks from local directory: /home/jovyan notebook_1 | [I 16:21:22.333 NotebookApp] The Jupyter Notebook is running at: notebook_1 | [I 16:21:22.333 NotebookApp] http://(9a7974f0ffb9 or 127.0.0.1):8888/?token=c9d7cb543a82a7a278197b874c789da99a7ed91cd2f84016 notebook_1 | [I 16:21:22.333 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation). notebook_1 | [C 16:21:22.339 NotebookApp] notebook_1 | notebook_1 | Copy/paste this URL into your browser when you connect for the first time, notebook_1 | to login with a token: notebook_1 | http://(9a7974f0ffb9 or 127.0.0.1):8888/?token=c9d7cb543a82a7a278197b874c789da99a7ed91cd2f84016 and then login and load the EPMT.ipynb file.","title":"Analysis and Visualization"},{"location":"INSTALL/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"INSTALL/#error-version-glibc_xxx-not-found","text":"The successful deployment of the collector libraries depends on the run-time environment of the target system. More plainly, this means, **do not compile papiex in your development environment, compile it with your target distributions environment. Each target environment should have their own separate papiex-oss-install directory. If you need to do otherwise, there are solutions involving deploying copies of additional libraries .","title":"Error: version GLIBC_x.xx not found"},{"location":"INSTALL/#appendix","text":"","title":"Appendix"},{"location":"INSTALL/#docker-images-for-the-running-the-epmt-command","text":"The image epmt-command is the image that contains a working epmt install and all it's dependencies. It's mean to be run as a command with arguments via docker run . See README.md for more details.","title":"Docker Images for the running the EPMT command"},{"location":"INSTALL/#testing-epmt-collection-with-various-python-versions-under-docker","text":"One can test EPMT on various versions of python with the following make commands. Each will test against a minimal install of Python, without installing any dependencies. make check-python-native make check-python-2.6 make check-python-2.7 make check-python-3","title":"Testing EPMT Collection with Various Python Versions under Docker"},{"location":"index_ui/","text":"EPMT Interface An interactive job viewer with experiment, component and job visualization. Features Recent Jobs - A table to display recently completed jobs associated metrics. Models - A table of models and correlated jobs, tags, features and creation date. Workflows - Visualizations from very broad working down to detailed analysis of jobs and experiments. Workflows 2 Workflows are available Metric based Timeline based. - Metrics Bar graphs of metrics Experiment Component Job 3 Page Workflow based on metrics - Timelines Gantt charts of jobs Experiment Component Job 3 Page Workflow","title":"Interface Readme"},{"location":"index_ui/#epmt-interface","text":"An interactive job viewer with experiment, component and job visualization.","title":"EPMT Interface"},{"location":"index_ui/#features","text":"Recent Jobs - A table to display recently completed jobs associated metrics. Models - A table of models and correlated jobs, tags, features and creation date. Workflows - Visualizations from very broad working down to detailed analysis of jobs and experiments.","title":"Features"},{"location":"index_ui/#workflows","text":"2 Workflows are available Metric based Timeline based.","title":"Workflows"},{"location":"index_ui/#-metrics","text":"Bar graphs of metrics Experiment Component Job 3 Page Workflow based on metrics","title":"- Metrics"},{"location":"index_ui/#-timelines","text":"Gantt charts of jobs Experiment Component Job 3 Page Workflow","title":"- Timelines"},{"location":"migrations/","text":"Database Migrations Migrations are supported for SQLAlchemy at present. We use alembic for migrations. Requirements SQLAlchemy ORM Preferably a database such as Postgres that supports ALTER SQLite works, but some migrations will give pain as SQLite doesn't support ALTER . Persistent database such as in file. We haven't tested in-memory configurations. Initial DB setup We have used alembic's auto-generate feature to create a baseline migration using the model definitions in orm/sqlalchemy/models.py . To achieve the automigration, we had to set target_metadata in migrations/env.py , and then run: alembic revision --autogenerate -m baseline This created migrations/versions/392efb1132ae_baseline.py . setup_db checks and applies this baseline migration if the database is empty. Once the database is setup, you can apply migrations as explained below. Creating a migration Let's follow an example that shows how to add a column to the users table. We will use an SQLite local-file database. # use the appropriate settings template $ cp settings/settings_sqlite_localfile_sqlalchemy.py settings.py # now create a migration file $ alembic revision -m add admin column to users table Generating /home/tushar/mm/epmt/build/epmt/migrations/versions/b1cf8c168491_add_admin_column_to_users_table.py ... done # Now edit the file, and add the following lines to upgrade and downgrade # functions in the generated file. def upgrade(): with op.batch_alter_table('users', schema=None) as batch_op: batch_op.add_column(sa.Column('is_admin', sa.Boolean(), nullable=True)) def downgrade(): with op.batch_alter_table('users', schema=None) as batch_op: batch_op.drop_column('is_admin') After the migration file has been update, we can run the migration. $ alembic upgrade head INFO [alembic.runtime.migration] Using sqlite:///db.sqlite INFO [alembic.runtime.migration] Context impl SQLiteImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. INFO [alembic.runtime.migration] Running upgrade - b1cf8c168491, add admin column to users table You can verify the column has been added to the database: $ echo .schema users | sqlite3 db.sqlite CREATE TABLE users ( created_at DATETIME, updated_at DATETIME, name VARCHAR NOT NULL, id INTEGER, info_dict JSON, is_admin BOOLEAN, PRIMARY KEY (name), CHECK (is_admin IN (0, 1)), CHECK (is_admin IN (0, 1)), UNIQUE (id) ); This only adds the column to the database. If you want to the column to be accessible in the object model, you WILL need to manually update the model definition in orm/sqlalchemy/models.py , and add something like: class User(db.Model): ... is_admin = db.Column(db.Boolean, default=False) To remove a migration To remove the latest migration, simply do: $ alembic downgrade -1 INFO [alembic.runtime.migration] Using sqlite:///db.sqlite INFO [alembic.runtime.migration] Context impl SQLiteImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. INFO [alembic.runtime.migration] Running downgrade b1cf8c168491 - , add admin column to users table You can verify the column has been removed: $ echo .schema users | sqlite3 db.sqlite CREATE TABLE users ( created_at DATETIME, updated_at DATETIME, name VARCHAR NOT NULL, id INTEGER, info_dict JSON, PRIMARY KEY (name), UNIQUE (id) ); To remove all migrations, do: $ alembic downgrade base References https://medium.com/the-andela-way/alembic-how-to-add-a-non-nullable-field-to-a-populated-table-998554003134 https://alembic.sqlalchemy.org/en/latest/batch.html","title":"Database Migrations"},{"location":"migrations/#database-migrations","text":"Migrations are supported for SQLAlchemy at present. We use alembic for migrations.","title":"Database Migrations"},{"location":"migrations/#requirements","text":"SQLAlchemy ORM Preferably a database such as Postgres that supports ALTER SQLite works, but some migrations will give pain as SQLite doesn't support ALTER . Persistent database such as in file. We haven't tested in-memory configurations.","title":"Requirements"},{"location":"migrations/#initial-db-setup","text":"We have used alembic's auto-generate feature to create a baseline migration using the model definitions in orm/sqlalchemy/models.py . To achieve the automigration, we had to set target_metadata in migrations/env.py , and then run: alembic revision --autogenerate -m baseline This created migrations/versions/392efb1132ae_baseline.py . setup_db checks and applies this baseline migration if the database is empty. Once the database is setup, you can apply migrations as explained below.","title":"Initial DB setup"},{"location":"migrations/#creating-a-migration","text":"Let's follow an example that shows how to add a column to the users table. We will use an SQLite local-file database. # use the appropriate settings template $ cp settings/settings_sqlite_localfile_sqlalchemy.py settings.py # now create a migration file $ alembic revision -m add admin column to users table Generating /home/tushar/mm/epmt/build/epmt/migrations/versions/b1cf8c168491_add_admin_column_to_users_table.py ... done # Now edit the file, and add the following lines to upgrade and downgrade # functions in the generated file. def upgrade(): with op.batch_alter_table('users', schema=None) as batch_op: batch_op.add_column(sa.Column('is_admin', sa.Boolean(), nullable=True)) def downgrade(): with op.batch_alter_table('users', schema=None) as batch_op: batch_op.drop_column('is_admin') After the migration file has been update, we can run the migration. $ alembic upgrade head INFO [alembic.runtime.migration] Using sqlite:///db.sqlite INFO [alembic.runtime.migration] Context impl SQLiteImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. INFO [alembic.runtime.migration] Running upgrade - b1cf8c168491, add admin column to users table You can verify the column has been added to the database: $ echo .schema users | sqlite3 db.sqlite CREATE TABLE users ( created_at DATETIME, updated_at DATETIME, name VARCHAR NOT NULL, id INTEGER, info_dict JSON, is_admin BOOLEAN, PRIMARY KEY (name), CHECK (is_admin IN (0, 1)), CHECK (is_admin IN (0, 1)), UNIQUE (id) ); This only adds the column to the database. If you want to the column to be accessible in the object model, you WILL need to manually update the model definition in orm/sqlalchemy/models.py , and add something like: class User(db.Model): ... is_admin = db.Column(db.Boolean, default=False)","title":"Creating a migration"},{"location":"migrations/#to-remove-a-migration","text":"To remove the latest migration, simply do: $ alembic downgrade -1 INFO [alembic.runtime.migration] Using sqlite:///db.sqlite INFO [alembic.runtime.migration] Context impl SQLiteImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. INFO [alembic.runtime.migration] Running downgrade b1cf8c168491 - , add admin column to users table You can verify the column has been removed: $ echo .schema users | sqlite3 db.sqlite CREATE TABLE users ( created_at DATETIME, updated_at DATETIME, name VARCHAR NOT NULL, id INTEGER, info_dict JSON, PRIMARY KEY (name), UNIQUE (id) ); To remove all migrations, do: $ alembic downgrade base","title":"To remove a migration"},{"location":"migrations/#references","text":"https://medium.com/the-andela-way/alembic-how-to-add-a-non-nullable-field-to-a-populated-table-998554003134 https://alembic.sqlalchemy.org/en/latest/batch.html","title":"References"}]}